{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5faae281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os \n",
    "import scipy.io as sio\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c3bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8f4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables   \n",
    "im_width, im_height, im_depth, im_channel = 15,15,30,1  #size of the input salinas patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c77d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(MAML,self).__init__()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    layers = [nn.Conv3d(1,8,(7,3,3))]\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(8))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(8,16,(5,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(16))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(16,32,(3,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(32))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(14400,256))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(256,128))\n",
    "    layers.append(nn.Linear(128,15))\n",
    "    self.model = nn.Sequential(*layers)\n",
    "  def forward(self,x) :\n",
    "    y = self.model(x)\n",
    "    z = self.softmax(y)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acdbb11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee854099",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model = MAML().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "815a76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat('Houston.mat')['Houston']\n",
    "        labels = sio.loadmat('Houston_gt.mat')['Houston_gt']\n",
    "    if name == 'salinas' :\n",
    "        data = sio.loadmat('Salinas.mat')['salinas']\n",
    "        labels = sio.loadmat('Salinas_gt.mat')['salinas_gt']\n",
    "    if name == 'Indian' :\n",
    "        data = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "        labels = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
    "    if name == 'ksc' :\n",
    "        data = sio.loadmat('KSC.mat')['KSC']\n",
    "        labels = sio.loadmat('KSC_gt.mat')['KSC_gt']\n",
    "    if name == 'botswana' :\n",
    "        data = sio.loadmat('Botswana.mat')['Botswana']\n",
    "        labels = sio.loadmat('Botswana_gt.mat')['Botswana_gt']\n",
    "    return data, labels\n",
    "# without reduction of 200 channels to 30 channels, memory error while creating cube \n",
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)  # X :(145, 145, 30) --> (195, 195, 30) with window =25\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))  # (21025, 25, 25, 30)   \n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))  # (21025,)\n",
    "    patchIndex = 0\n",
    "    \n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]  \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]            \n",
    "            patchIndex = patchIndex + 1\n",
    "  \n",
    "    patchesData = np.expand_dims(patchesData, axis=-1)\n",
    "    return patchesData,patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aea8e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21025, 15, 15, 30, 1) (21025,)\n"
     ]
    }
   ],
   "source": [
    "# creating input patches from the salinas dataset \n",
    "dataset1IP = 'Indian'                                         # 16 classes   \n",
    "sa_x1IP, sa_yIP = loadData(dataset1IP)                              #((512, 217, 204), (512, 217))\n",
    "sa_x2IP,pca = applyPCA(sa_x1IP,numComponents=30)                   # ((512, 217, 20), (512, 217))\n",
    "sa_XIP,sa_YIP = createImageCubes(sa_x2IP, sa_yIP, windowSize=15)   #(111104, 9, 9, 20, 1) (111104,)\n",
    "print(sa_XIP.shape,sa_YIP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eed6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches_class(X,Y,n) :\n",
    "  n_classes = n\n",
    "  patches_list = []\n",
    "  for i in range(1,n_classes+1):   # not considering class 0\n",
    "    patchesData_Ith_Label = X[Y==i,:,:,:,:]\n",
    "    patches_list.append(patchesData_Ith_Label)\n",
    "  return patches_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88875fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_salinas = patches_class(sa_X,sa_Y,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69db85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_IP = patches_class(sa_XIP,sa_YIP,16)#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f8ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "test_class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "train_patches_class = [patches_class_salinas[i] for i in train_class_indices]        #(10)\n",
    "test_patches_class = [patches_class_IP[i] for i in test_class_indices]        #(6) \n",
    "train_class_labels = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]   \n",
    "test_class_labels = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a964d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 15  # n_class\n",
    "K1 = 10   # n_support\n",
    "N = 20   # n_query\n",
    "tC = 16  # classes in a test episode\n",
    "im_height,im_width,im_depth = 15,15,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb1974a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_opt = torch.optim.Adam(maml_model.parameters(), lr=0.0001, betas=(0.5, 0.999))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e84296bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43944ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    np.random.shuffle(test_patches_class[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bc498b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_set_5 = [[] for i in range(16)]\n",
    "for j in range(16) :\n",
    "  tune_set_5[j] = test_patches_class[j][:10,:,:,:,:]   # for each class first 5 samples taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb79bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(10, 15, 15, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(tune_set_5))\n",
    "print(tune_set_5[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c2b3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3214ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_episode(tune_set,tK,tN,test_class_labels) :\n",
    "  selected_classes = test_class_labels\n",
    "  support_labels  = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    np.random.shuffle(tune_set[y])    \n",
    "    support_imgs = tune_set[y][:tK,:,:,:,:]    #Support 1, Query 4\n",
    "    query_imgs = tune_set[y][tK:10,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(tN) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(tK) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(tC*tN,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(tC*tK,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels, list(selected_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd741d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixa = 'houston2/ckpts/ckpt399439479'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82ca0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir2 = 'tuninghoustonip/ckpts'\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54b3e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixa)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80f32eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model=nn.Sequential(*list(maml_model.model.children())[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7baadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra0',nn.Linear(46656,256))\n",
    "maml_model.model.add_module('extra1',nn.Dropout(0.5))\n",
    "maml_model.model.add_module('extra2',nn.Linear(256,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96fc771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra4',nn.Linear(128,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b3cbec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAML(\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (model): Sequential(\n",
       "    (0): Conv3d(1, 8, kernel_size=(7, 3, 3), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Conv3d(8, 16, kernel_size=(5, 3, 3), stride=(1, 1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Flatten(start_dim=1, end_dim=-1)\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (extra0): Linear(in_features=46656, out_features=256, bias=True)\n",
       "    (extra1): Dropout(p=0.5, inplace=False)\n",
       "    (extra2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (extra4): Linear(in_features=128, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maml_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c739d80-fc30-43ba-b83d-d01d3d568523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img, length, num_band):\n",
    "\n",
    "\n",
    "    c, h, w = np.shape(img)[2], np.shape(img)[3], np.shape(img)[4]\n",
    "\n",
    "    data = img\n",
    "    RandPerm = np.random.permutation(c)\n",
    "    for i in range(len(RandPerm)//num_band):\n",
    "        img_c = img[RandPerm[i], :, :]\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "\n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "\n",
    "        mask[y1: y2, x1: x2] = 0\n",
    "\n",
    "        img_c *= mask\n",
    "        img_c = img_c[np.newaxis, :, :]\n",
    "        data[RandPerm[i], :, :] = img_c\n",
    "\n",
    "    img[2]=data[0]\n",
    "    img[3]=data[1]\n",
    "    img[4]=data[2]\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c64a131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss tensor(38.0343, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6188, dtype=torch.float64)\n",
      "1 Loss tensor(37.7649, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6367, dtype=torch.float64)\n",
      "2 Loss tensor(37.4195, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6445, dtype=torch.float64)\n",
      "3 Loss tensor(37.2344, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6547, dtype=torch.float64)\n",
      "4 Loss tensor(36.9912, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6766, dtype=torch.float64)\n",
      "5 Loss tensor(36.8372, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6734, dtype=torch.float64)\n",
      "6 Loss tensor(36.6653, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6805, dtype=torch.float64)\n",
      "7 Loss tensor(36.7536, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6727, dtype=torch.float64)\n",
      "8 Loss tensor(36.5302, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6938, dtype=torch.float64)\n",
      "9 Loss tensor(36.3666, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6937, dtype=torch.float64)\n",
      "10 Loss tensor(36.1750, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7023, dtype=torch.float64)\n",
      "11 Loss tensor(36.0540, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7133, dtype=torch.float64)\n",
      "12 Loss tensor(36.1259, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7031, dtype=torch.float64)\n",
      "13 Loss tensor(35.9014, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7266, dtype=torch.float64)\n",
      "14 Loss tensor(35.9083, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7148, dtype=torch.float64)\n",
      "15 Loss tensor(35.9134, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7172, dtype=torch.float64)\n",
      "16 Loss tensor(35.8431, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7250, dtype=torch.float64)\n",
      "17 Loss tensor(35.7790, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7227, dtype=torch.float64)\n",
      "18 Loss tensor(35.8632, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7133, dtype=torch.float64)\n",
      "19 Loss tensor(35.7584, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7297, dtype=torch.float64)\n",
      "20 Loss tensor(35.8213, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7234, dtype=torch.float64)\n",
      "21 Loss tensor(35.6586, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7305, dtype=torch.float64)\n",
      "22 Loss tensor(35.6906, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7312, dtype=torch.float64)\n",
      "23 Loss tensor(35.5745, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7492, dtype=torch.float64)\n",
      "24 Loss tensor(35.6575, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7289, dtype=torch.float64)\n",
      "25 Loss tensor(35.6413, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7289, dtype=torch.float64)\n",
      "26 Loss tensor(35.4344, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7555, dtype=torch.float64)\n",
      "27 Loss tensor(35.4517, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7484, dtype=torch.float64)\n",
      "28 Loss tensor(35.6511, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7367, dtype=torch.float64)\n",
      "29 Loss tensor(35.6841, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7250, dtype=torch.float64)\n",
      "30 Loss tensor(35.3496, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7547, dtype=torch.float64)\n",
      "31 Loss tensor(35.3793, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7461, dtype=torch.float64)\n",
      "32 Loss tensor(35.4653, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7461, dtype=torch.float64)\n",
      "33 Loss tensor(35.4959, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7484, dtype=torch.float64)\n",
      "34 Loss tensor(35.4277, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7320, dtype=torch.float64)\n",
      "35 Loss tensor(35.1654, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7641, dtype=torch.float64)\n",
      "36 Loss tensor(35.4663, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7445, dtype=torch.float64)\n",
      "37 Loss tensor(35.2182, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7539, dtype=torch.float64)\n",
      "38 Loss tensor(35.1904, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7680, dtype=torch.float64)\n",
      "39 Loss tensor(35.1490, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7688, dtype=torch.float64)\n",
      "40 Loss tensor(35.4729, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7414, dtype=torch.float64)\n",
      "41 Loss tensor(35.1932, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7531, dtype=torch.float64)\n",
      "42 Loss tensor(35.4475, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7344, dtype=torch.float64)\n",
      "43 Loss tensor(35.3315, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7422, dtype=torch.float64)\n",
      "44 Loss tensor(34.9282, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7852, dtype=torch.float64)\n",
      "45 Loss tensor(35.1443, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7570, dtype=torch.float64)\n",
      "46 Loss tensor(35.1300, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7617, dtype=torch.float64)\n",
      "47 Loss tensor(34.9815, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7758, dtype=torch.float64)\n",
      "48 Loss tensor(35.0400, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7727, dtype=torch.float64)\n",
      "49 Loss tensor(35.0940, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7594, dtype=torch.float64)\n",
      "50 Loss tensor(35.0375, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7555, dtype=torch.float64)\n",
      "51 Loss tensor(35.2805, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7586, dtype=torch.float64)\n",
      "52 Loss tensor(35.0191, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7734, dtype=torch.float64)\n",
      "53 Loss tensor(34.9511, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7828, dtype=torch.float64)\n",
      "54 Loss tensor(35.0009, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7719, dtype=torch.float64)\n",
      "55 Loss tensor(34.9371, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7750, dtype=torch.float64)\n",
      "56 Loss tensor(34.9497, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7695, dtype=torch.float64)\n",
      "57 Loss tensor(35.1138, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7578, dtype=torch.float64)\n",
      "58 Loss tensor(34.7953, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7852, dtype=torch.float64)\n",
      "59 Loss tensor(34.8544, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7836, dtype=torch.float64)\n",
      "60 Loss tensor(34.9872, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7773, dtype=torch.float64)\n",
      "61 Loss tensor(34.9228, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7852, dtype=torch.float64)\n",
      "62 Loss tensor(34.9501, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7695, dtype=torch.float64)\n",
      "63 Loss tensor(34.8933, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7789, dtype=torch.float64)\n",
      "64 Loss tensor(34.8063, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7898, dtype=torch.float64)\n",
      "65 Loss tensor(34.9692, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7680, dtype=torch.float64)\n",
      "66 Loss tensor(34.9874, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7703, dtype=torch.float64)\n",
      "67 Loss tensor(34.9173, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7672, dtype=torch.float64)\n",
      "68 Loss tensor(34.7989, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7844, dtype=torch.float64)\n",
      "69 Loss tensor(34.8718, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7773, dtype=torch.float64)\n",
      "70 Loss tensor(34.8899, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7766, dtype=torch.float64)\n",
      "71 Loss tensor(34.6945, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7898, dtype=torch.float64)\n",
      "72 Loss tensor(34.6672, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7937, dtype=torch.float64)\n",
      "73 Loss tensor(34.7127, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7883, dtype=torch.float64)\n",
      "74 Loss tensor(34.8911, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7742, dtype=torch.float64)\n",
      "75 Loss tensor(34.7071, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7898, dtype=torch.float64)\n",
      "76 Loss tensor(34.5833, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7969, dtype=torch.float64)\n",
      "77 Loss tensor(34.7791, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7906, dtype=torch.float64)\n",
      "78 Loss tensor(34.5327, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8078, dtype=torch.float64)\n",
      "79 Loss tensor(34.8069, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7820, dtype=torch.float64)\n",
      "80 Loss tensor(34.5989, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7984, dtype=torch.float64)\n",
      "81 Loss tensor(34.6776, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7867, dtype=torch.float64)\n",
      "82 Loss tensor(34.5821, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7977, dtype=torch.float64)\n",
      "83 Loss tensor(34.6432, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7945, dtype=torch.float64)\n",
      "84 Loss tensor(34.7434, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7836, dtype=torch.float64)\n",
      "85 Loss tensor(34.7258, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7859, dtype=torch.float64)\n",
      "86 Loss tensor(34.5564, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7969, dtype=torch.float64)\n",
      "87 Loss tensor(34.5365, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7977, dtype=torch.float64)\n",
      "88 Loss tensor(34.5936, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8008, dtype=torch.float64)\n",
      "89 Loss tensor(34.5440, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8078, dtype=torch.float64)\n",
      "90 Loss tensor(34.4471, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7977, dtype=torch.float64)\n",
      "91 Loss tensor(34.7486, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7914, dtype=torch.float64)\n",
      "92 Loss tensor(34.6040, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7906, dtype=torch.float64)\n",
      "93 Loss tensor(34.5882, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7937, dtype=torch.float64)\n",
      "94 Loss tensor(34.5993, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7953, dtype=torch.float64)\n",
      "95 Loss tensor(34.6504, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8008, dtype=torch.float64)\n",
      "96 Loss tensor(34.6166, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7781, dtype=torch.float64)\n",
      "97 Loss tensor(34.4506, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7953, dtype=torch.float64)\n",
      "98 Loss tensor(34.4430, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "99 Loss tensor(34.4776, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8016, dtype=torch.float64)\n",
      "100 Loss tensor(34.3988, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8055, dtype=torch.float64)\n",
      "101 Loss tensor(34.3729, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8195, dtype=torch.float64)\n",
      "102 Loss tensor(34.2738, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8109, dtype=torch.float64)\n",
      "103 Loss tensor(34.3125, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8133, dtype=torch.float64)\n",
      "104 Loss tensor(34.5988, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7875, dtype=torch.float64)\n",
      "105 Loss tensor(34.3326, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8086, dtype=torch.float64)\n",
      "106 Loss tensor(34.3031, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8141, dtype=torch.float64)\n",
      "107 Loss tensor(34.5636, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7922, dtype=torch.float64)\n",
      "108 Loss tensor(34.3812, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8109, dtype=torch.float64)\n",
      "109 Loss tensor(34.3210, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8078, dtype=torch.float64)\n",
      "110 Loss tensor(34.3960, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8062, dtype=torch.float64)\n",
      "111 Loss tensor(34.4989, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8031, dtype=torch.float64)\n",
      "112 Loss tensor(34.4127, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8047, dtype=torch.float64)\n",
      "113 Loss tensor(34.3076, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8117, dtype=torch.float64)\n",
      "114 Loss tensor(34.2892, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8141, dtype=torch.float64)\n",
      "115 Loss tensor(34.5340, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7969, dtype=torch.float64)\n",
      "116 Loss tensor(34.3346, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8016, dtype=torch.float64)\n",
      "117 Loss tensor(34.3478, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8031, dtype=torch.float64)\n",
      "118 Loss tensor(34.3210, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8148, dtype=torch.float64)\n",
      "119 Loss tensor(34.1077, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8266, dtype=torch.float64)\n",
      "120 Loss tensor(34.3906, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7992, dtype=torch.float64)\n",
      "121 Loss tensor(34.2939, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8086, dtype=torch.float64)\n",
      "122 Loss tensor(34.4356, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8125, dtype=torch.float64)\n",
      "123 Loss tensor(34.3674, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8078, dtype=torch.float64)\n",
      "124 Loss tensor(34.3989, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8070, dtype=torch.float64)\n",
      "125 Loss tensor(34.3909, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8008, dtype=torch.float64)\n",
      "126 Loss tensor(34.2980, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8133, dtype=torch.float64)\n",
      "127 Loss tensor(34.2933, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8125, dtype=torch.float64)\n",
      "128 Loss tensor(34.4958, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7852, dtype=torch.float64)\n",
      "129 Loss tensor(34.4182, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8063, dtype=torch.float64)\n",
      "130 Loss tensor(34.3522, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8039, dtype=torch.float64)\n",
      "131 Loss tensor(34.2954, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8086, dtype=torch.float64)\n",
      "132 Loss tensor(34.1705, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8219, dtype=torch.float64)\n",
      "133 Loss tensor(33.9268, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8289, dtype=torch.float64)\n",
      "134 Loss tensor(34.1913, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8086, dtype=torch.float64)\n",
      "135 Loss tensor(34.2915, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8102, dtype=torch.float64)\n",
      "136 Loss tensor(34.5497, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7937, dtype=torch.float64)\n",
      "137 Loss tensor(33.9323, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8336, dtype=torch.float64)\n",
      "138 Loss tensor(34.2624, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8148, dtype=torch.float64)\n",
      "139 Loss tensor(34.3585, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8039, dtype=torch.float64)\n",
      "140 Loss tensor(34.1235, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8164, dtype=torch.float64)\n",
      "141 Loss tensor(34.2646, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8141, dtype=torch.float64)\n",
      "142 Loss tensor(34.2746, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8039, dtype=torch.float64)\n",
      "143 Loss tensor(34.3126, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8094, dtype=torch.float64)\n",
      "144 Loss tensor(34.2148, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8117, dtype=torch.float64)\n",
      "145 Loss tensor(34.2056, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8211, dtype=torch.float64)\n",
      "146 Loss tensor(34.4213, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7937, dtype=torch.float64)\n",
      "147 Loss tensor(34.3627, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7945, dtype=torch.float64)\n",
      "148 Loss tensor(34.0862, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8203, dtype=torch.float64)\n",
      "149 Loss tensor(34.0815, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8219, dtype=torch.float64)\n",
      "150 Loss tensor(34.2610, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8258, dtype=torch.float64)\n",
      "151 Loss tensor(34.1772, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8109, dtype=torch.float64)\n",
      "152 Loss tensor(34.2184, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8094, dtype=torch.float64)\n",
      "153 Loss tensor(34.1653, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8164, dtype=torch.float64)\n",
      "154 Loss tensor(33.9178, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8320, dtype=torch.float64)\n",
      "155 Loss tensor(34.1670, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8156, dtype=torch.float64)\n",
      "156 Loss tensor(34.2247, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8102, dtype=torch.float64)\n",
      "157 Loss tensor(34.0335, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8273, dtype=torch.float64)\n",
      "158 Loss tensor(34.1086, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8180, dtype=torch.float64)\n",
      "159 Loss tensor(34.1497, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8258, dtype=torch.float64)\n",
      "160 Loss tensor(34.2651, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8102, dtype=torch.float64)\n",
      "161 Loss tensor(34.0246, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8305, dtype=torch.float64)\n",
      "162 Loss tensor(34.1049, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8242, dtype=torch.float64)\n",
      "163 Loss tensor(34.0489, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8266, dtype=torch.float64)\n",
      "164 Loss tensor(34.1703, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8219, dtype=torch.float64)\n",
      "165 Loss tensor(34.2713, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8125, dtype=torch.float64)\n",
      "166 Loss tensor(34.1163, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8148, dtype=torch.float64)\n",
      "167 Loss tensor(34.0327, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8359, dtype=torch.float64)\n",
      "168 Loss tensor(34.1716, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8195, dtype=torch.float64)\n",
      "169 Loss tensor(34.0088, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8344, dtype=torch.float64)\n",
      "170 Loss tensor(34.1568, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8242, dtype=torch.float64)\n",
      "171 Loss tensor(34.4108, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "172 Loss tensor(33.9986, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8172, dtype=torch.float64)\n",
      "173 Loss tensor(33.6922, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "174 Loss tensor(33.9664, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8305, dtype=torch.float64)\n",
      "175 Loss tensor(33.9833, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8289, dtype=torch.float64)\n",
      "176 Loss tensor(33.9986, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8250, dtype=torch.float64)\n",
      "177 Loss tensor(33.9666, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8305, dtype=torch.float64)\n",
      "178 Loss tensor(34.0755, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8320, dtype=torch.float64)\n",
      "179 Loss tensor(34.0043, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8203, dtype=torch.float64)\n",
      "180 Loss tensor(33.8222, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8313, dtype=torch.float64)\n",
      "181 Loss tensor(33.9171, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8344, dtype=torch.float64)\n",
      "182 Loss tensor(34.0388, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8281, dtype=torch.float64)\n",
      "183 Loss tensor(33.8569, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8344, dtype=torch.float64)\n",
      "184 Loss tensor(33.8817, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8289, dtype=torch.float64)\n",
      "185 Loss tensor(33.8057, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8383, dtype=torch.float64)\n",
      "186 Loss tensor(34.0369, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8297, dtype=torch.float64)\n",
      "187 Loss tensor(34.0238, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8258, dtype=torch.float64)\n",
      "188 Loss tensor(33.8725, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8375, dtype=torch.float64)\n",
      "189 Loss tensor(33.9440, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8352, dtype=torch.float64)\n",
      "190 Loss tensor(33.9763, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8336, dtype=torch.float64)\n",
      "191 Loss tensor(33.9752, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8297, dtype=torch.float64)\n",
      "192 Loss tensor(33.9808, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8258, dtype=torch.float64)\n",
      "193 Loss tensor(34.2273, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8023, dtype=torch.float64)\n",
      "194 Loss tensor(33.9496, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8266, dtype=torch.float64)\n",
      "195 Loss tensor(33.7870, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8461, dtype=torch.float64)\n",
      "196 Loss tensor(33.8528, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8297, dtype=torch.float64)\n",
      "197 Loss tensor(33.9275, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8203, dtype=torch.float64)\n",
      "198 Loss tensor(34.0616, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8203, dtype=torch.float64)\n",
      "199 Loss tensor(33.8255, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8453, dtype=torch.float64)\n",
      "200 Loss tensor(34.0515, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8227, dtype=torch.float64)\n",
      "201 Loss tensor(33.9147, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8266, dtype=torch.float64)\n",
      "202 Loss tensor(33.7431, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8391, dtype=torch.float64)\n",
      "203 Loss tensor(33.8377, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8328, dtype=torch.float64)\n",
      "204 Loss tensor(33.9232, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8375, dtype=torch.float64)\n",
      "205 Loss tensor(33.9870, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8219, dtype=torch.float64)\n",
      "206 Loss tensor(33.7706, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8438, dtype=torch.float64)\n",
      "207 Loss tensor(33.7971, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8336, dtype=torch.float64)\n",
      "208 Loss tensor(33.6116, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8477, dtype=torch.float64)\n",
      "209 Loss tensor(33.8840, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8273, dtype=torch.float64)\n",
      "210 Loss tensor(33.9103, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8305, dtype=torch.float64)\n",
      "211 Loss tensor(33.7484, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8383, dtype=torch.float64)\n",
      "212 Loss tensor(33.8508, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8281, dtype=torch.float64)\n",
      "213 Loss tensor(33.6978, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8492, dtype=torch.float64)\n",
      "214 Loss tensor(33.8939, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8313, dtype=torch.float64)\n",
      "215 Loss tensor(33.7171, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8367, dtype=torch.float64)\n",
      "216 Loss tensor(33.8924, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8391, dtype=torch.float64)\n",
      "217 Loss tensor(33.6827, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8438, dtype=torch.float64)\n",
      "218 Loss tensor(33.7058, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8422, dtype=torch.float64)\n",
      "219 Loss tensor(33.8352, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8297, dtype=torch.float64)\n",
      "220 Loss tensor(33.7340, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8445, dtype=torch.float64)\n",
      "221 Loss tensor(33.7596, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8430, dtype=torch.float64)\n",
      "222 Loss tensor(33.7998, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8375, dtype=torch.float64)\n",
      "223 Loss tensor(33.7136, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8453, dtype=torch.float64)\n",
      "224 Loss tensor(33.6598, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8523, dtype=torch.float64)\n",
      "225 Loss tensor(33.7720, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8391, dtype=torch.float64)\n",
      "226 Loss tensor(33.6509, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8438, dtype=torch.float64)\n",
      "227 Loss tensor(33.5975, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8484, dtype=torch.float64)\n",
      "228 Loss tensor(33.4364, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8641, dtype=torch.float64)\n",
      "229 Loss tensor(33.7791, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8383, dtype=torch.float64)\n",
      "230 Loss tensor(33.6406, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8523, dtype=torch.float64)\n",
      "231 Loss tensor(33.5837, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8445, dtype=torch.float64)\n",
      "232 Loss tensor(33.7702, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8391, dtype=torch.float64)\n",
      "233 Loss tensor(33.8197, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8398, dtype=torch.float64)\n",
      "234 Loss tensor(33.8142, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8391, dtype=torch.float64)\n",
      "235 Loss tensor(33.6796, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8438, dtype=torch.float64)\n",
      "236 Loss tensor(33.7921, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8320, dtype=torch.float64)\n",
      "237 Loss tensor(33.7255, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8398, dtype=torch.float64)\n",
      "238 Loss tensor(33.6485, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8461, dtype=torch.float64)\n",
      "239 Loss tensor(33.5383, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8555, dtype=torch.float64)\n",
      "240 Loss tensor(33.8495, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8430, dtype=torch.float64)\n",
      "241 Loss tensor(33.7216, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8391, dtype=torch.float64)\n",
      "242 Loss tensor(33.7176, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8484, dtype=torch.float64)\n",
      "243 Loss tensor(33.5135, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8516, dtype=torch.float64)\n",
      "244 Loss tensor(33.8063, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8305, dtype=torch.float64)\n",
      "245 Loss tensor(33.7138, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8398, dtype=torch.float64)\n",
      "246 Loss tensor(33.7506, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8438, dtype=torch.float64)\n",
      "247 Loss tensor(33.7436, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8375, dtype=torch.float64)\n",
      "248 Loss tensor(33.6268, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8547, dtype=torch.float64)\n",
      "249 Loss tensor(33.7218, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8336, dtype=torch.float64)\n",
      "250 Loss tensor(33.8092, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8352, dtype=torch.float64)\n",
      "251 Loss tensor(33.6051, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8500, dtype=torch.float64)\n",
      "252 Loss tensor(33.6703, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8609, dtype=torch.float64)\n",
      "253 Loss tensor(33.7417, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8383, dtype=torch.float64)\n",
      "254 Loss tensor(33.7068, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8383, dtype=torch.float64)\n",
      "255 Loss tensor(33.6498, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8484, dtype=torch.float64)\n",
      "256 Loss tensor(33.6090, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8477, dtype=torch.float64)\n",
      "257 Loss tensor(33.5585, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8547, dtype=torch.float64)\n",
      "258 Loss tensor(33.5993, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8484, dtype=torch.float64)\n",
      "259 Loss tensor(33.5245, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8719, dtype=torch.float64)\n",
      "260 Loss tensor(33.8032, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8406, dtype=torch.float64)\n",
      "261 Loss tensor(33.4734, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8617, dtype=torch.float64)\n",
      "262 Loss tensor(33.4694, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8570, dtype=torch.float64)\n",
      "263 Loss tensor(33.5908, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8609, dtype=torch.float64)\n",
      "264 Loss tensor(33.3210, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8656, dtype=torch.float64)\n",
      "265 Loss tensor(33.5206, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8516, dtype=torch.float64)\n",
      "266 Loss tensor(33.5796, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8500, dtype=torch.float64)\n",
      "267 Loss tensor(33.5222, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8578, dtype=torch.float64)\n",
      "268 Loss tensor(33.5499, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8562, dtype=torch.float64)\n",
      "269 Loss tensor(33.5146, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8570, dtype=torch.float64)\n",
      "270 Loss tensor(33.6986, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8422, dtype=torch.float64)\n",
      "271 Loss tensor(33.6000, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8430, dtype=torch.float64)\n",
      "272 Loss tensor(33.2270, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8758, dtype=torch.float64)\n",
      "273 Loss tensor(33.5776, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8547, dtype=torch.float64)\n",
      "274 Loss tensor(33.6800, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8484, dtype=torch.float64)\n",
      "275 Loss tensor(33.5688, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8500, dtype=torch.float64)\n",
      "276 Loss tensor(33.4838, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8609, dtype=torch.float64)\n",
      "277 Loss tensor(33.6854, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8422, dtype=torch.float64)\n",
      "278 Loss tensor(33.5972, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8445, dtype=torch.float64)\n",
      "279 Loss tensor(33.4404, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8562, dtype=torch.float64)\n",
      "280 Loss tensor(33.5572, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8516, dtype=torch.float64)\n",
      "281 Loss tensor(33.4212, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8625, dtype=torch.float64)\n",
      "282 Loss tensor(33.4490, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8461, dtype=torch.float64)\n",
      "283 Loss tensor(33.5182, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8547, dtype=torch.float64)\n",
      "284 Loss tensor(33.5006, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8570, dtype=torch.float64)\n",
      "285 Loss tensor(33.6629, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8383, dtype=torch.float64)\n",
      "286 Loss tensor(33.5060, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8609, dtype=torch.float64)\n",
      "287 Loss tensor(33.6801, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8453, dtype=torch.float64)\n",
      "288 Loss tensor(33.5828, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8500, dtype=torch.float64)\n",
      "289 Loss tensor(33.4710, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8523, dtype=torch.float64)\n",
      "290 Loss tensor(33.4697, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8609, dtype=torch.float64)\n",
      "291 Loss tensor(33.6254, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8359, dtype=torch.float64)\n",
      "292 Loss tensor(33.5646, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "293 Loss tensor(33.4755, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8562, dtype=torch.float64)\n",
      "294 Loss tensor(33.4047, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8688, dtype=torch.float64)\n",
      "295 Loss tensor(33.4399, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8617, dtype=torch.float64)\n",
      "296 Loss tensor(33.6150, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8531, dtype=torch.float64)\n",
      "297 Loss tensor(33.5060, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8484, dtype=torch.float64)\n",
      "298 Loss tensor(33.5118, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8516, dtype=torch.float64)\n",
      "299 Loss tensor(33.4679, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8656, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "n_episodes = 300\n",
    "epochs = 300\n",
    "import higher\n",
    "n_tasks = 16\n",
    "K2 = 5\n",
    "N2 = 5\n",
    "\n",
    "for k in range(epochs) :\n",
    "    tune_accuracies = []\n",
    "    maml_model.train()\n",
    "    total_loss = 0\n",
    "    accuracies = []\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        query_patches, support_patches, query_labels, support_labels, selected_classes = tune_episode(tune_set_5,5,5,test_class_labels)        \n",
    "        support_patches = cutout(support_patches, 2, 10)\n",
    "        query_patches = cutout(query_patches, 2, 10)\n",
    "        support_y = np.zeros((int(C*K2),C))\n",
    "        support_patches = support_patches.to(device)\n",
    "        query_patches = query_patches.to(device)                                           \n",
    "        for i in range(int(C*K2)) :\n",
    "          x = selected_classes.index(support_labels[i])                           # creation of 1-hot for true labels\n",
    "          support_y[i][x] = 1. \n",
    "        support_y = torch.from_numpy(support_y).to(device)\n",
    "        query_y = np.zeros((int(C*N2),C))                                           \n",
    "        for i in range(int(C*N2)) :\n",
    "          x = selected_classes.index(query_labels[i])                           # creation of 1-hot for true labels\n",
    "          query_y[i][x] = 1.\n",
    "        query_y = torch.from_numpy(query_y).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(support_patches)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss)\n",
    "        q_logits = fnet(query_patches)\n",
    "        q_real = query_y.argmax(axis=1)\n",
    "        q_real = (q_real).long()\n",
    "        q_loss = F.cross_entropy(q_logits,q_real)\n",
    "        qzq2_loss = q_loss\n",
    "        qzq2_loss.detach()\n",
    "        total_loss += qzq2_loss\n",
    "        qzq2_loss.backward()\n",
    "        eq = (q_logits.argmax(dim=1) == q_real).sum().item()\n",
    "        accuracy = eq/len(q_real)  \n",
    "        tune_accuracies.append(accuracy)\n",
    "    meta_opt.step()\n",
    "    tune_accuracies = torch.from_numpy(np.asarray(tune_accuracies))\n",
    "    print(k,'Loss',total_loss,..., 'Accuracy', torch.mean(tune_accuracies))\n",
    "    if (k+1)%2==0 :\n",
    "       torch.save({'model_state_dict': maml_model.state_dict(),\n",
    "            'optimizer_state_dict': meta_opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "            }, checkpoint_prefix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0995be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_episode(test_patches_class,test_class_labels,test_C,test_K) :\n",
    "  selected_classes = test_class_labels # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  support_labels = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    support_imgs = test_patches_class[y][:test_K,:,:,:,:]\n",
    "    query_imgs = test_patches_class[y][test_K:,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(query_imgs.shape[0]) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(test_K) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  x = len(query_labels)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(x,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(test_C*test_K,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels,x, list(selected_classes)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbbcb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tquery_patches, tsupport_patches, tquery_labels, tsupport_labels, x, tselected_classes = test_episode(test_patches_class,test_class_labels,16,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdaa8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixb = 'tuninghoustonip/ckpts/ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c345e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixb)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8898eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c6505df-07e0-4635-acfb-b0a900f824f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7214788383387848\n",
      "[1.0]\n",
      "[0.580394922425952]\n",
      "[0.7463414634146341]\n",
      "[0.9559471365638766]\n",
      "[0.8816067653276956]\n",
      "[0.9777777777777777]\n",
      "[1.0]\n",
      "[0.9935897435897436]\n",
      "[1.0]\n",
      "[0.6174636174636174]\n",
      "[0.6073619631901841]\n",
      "[0.41680960548885077]\n",
      "[1.0]\n",
      "[0.8318725099601594]\n",
      "[0.8856382978723404]\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C = 16\n",
    "for epoch in range(1): \n",
    "    import higher   \n",
    "    n_tasks = 1\n",
    "    total_loss = 0\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1, selected_classes1 = test_episode(test_patches_class,test_class_labels,16,5)        \n",
    "        support_y1 = np.zeros((int(C*K1),C))\n",
    "        tsupport_patches1 = tsupport_patches1.to(device)\n",
    "        tquery_patches1 = tquery_patches1.to(device)                                             \n",
    "        for i in range(int(C*K1)) :\n",
    "          x = selected_classes1.index(support_labels1[i])                           # creation of 1-hot for true labels\n",
    "          support_y1[i][x] = 1. \n",
    "        support_y1 = torch.from_numpy(support_y1).to(device)\n",
    "        query_y1 = np.zeros((int(x1),C))                                         \n",
    "        for i in range(int(x1)) :\n",
    "          x = selected_classes1.index(query_labels1[i])                           # creation of 1-hot for true labels\n",
    "          query_y1[i][x] = 1.\n",
    "        query_y1 = torch.from_numpy(query_y1).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(tsupport_patches1)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y1.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss2 = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss2)\n",
    "        q_logits1 = fnet(tquery_patches1)\n",
    "        q_real1 = query_y1.argmax(axis=1)\n",
    "        q_real1 = (q_real1).long()\n",
    "        q_loss = F.cross_entropy(q_logits1,q_real1)\n",
    "        qzq3_loss = q_loss\n",
    "        qzq3_loss.detach()\n",
    "        total_loss += qzq3_loss\n",
    "        #q_loss.backward()\n",
    "        eq1 = (q_logits1.argmax(dim=1) == q_real1).sum().item()\n",
    "        accuracy1 = eq1/len(q_real1)  \n",
    "        print(accuracy1) \n",
    "        mean_correct_class = [[] for i in range(C)]\n",
    "        mean_correct_pred = [[] for i in range(C)]\n",
    "        classwise_mean_acc = [[] for i in range(C)]\n",
    "        q_pred = q_logits1.argmax(dim=1)\n",
    "        for i in range(int(x1)):\n",
    "          x = selected_classes1.index(query_labels1[i])\n",
    "          mean_correct_class[x].append('4')\n",
    "          if(q_pred[i] == x) :\n",
    "            mean_correct_pred[x].append('4')\n",
    "        for i in range(C) :\n",
    "           z = len(mean_correct_pred[i])/len(mean_correct_class[i])\n",
    "           classwise_mean_acc[i].append(z)\n",
    "           print(classwise_mean_acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4de2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

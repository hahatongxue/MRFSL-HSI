{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faae281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os \n",
    "import scipy.io as sio\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables   \n",
    "im_width, im_height, im_depth, im_channel = 15,15,30,1  #size of the input salinas patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(MAML,self).__init__()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    layers = [nn.Conv3d(1,8,(7,3,3))]\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(8))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(8,16,(5,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(16))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(16,32,(3,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(32))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(14400,256))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(256,128))\n",
    "    layers.append(nn.Linear(128,15))\n",
    "    self.model = nn.Sequential(*layers)\n",
    "  def forward(self,x) :\n",
    "    y = self.model(x)\n",
    "    z = self.softmax(y)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee854099",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model = MAML().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat('Houston.mat')['Houston']\n",
    "        labels = sio.loadmat('Houston_gt.mat')['Houston_gt']\n",
    "    if name == 'salinas' :\n",
    "        data = sio.loadmat('Salinas.mat')['salinas']\n",
    "        labels = sio.loadmat('Salinas_gt.mat')['salinas_gt']\n",
    "    if name == 'Indian' :\n",
    "        data = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "        labels = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
    "    if name == 'ksc' :\n",
    "        data = sio.loadmat('KSC.mat')['KSC']\n",
    "        labels = sio.loadmat('KSC_gt.mat')['KSC_gt']\n",
    "    if name == 'botswana' :\n",
    "        data = sio.loadmat('Botswana.mat')['Botswana']\n",
    "        labels = sio.loadmat('Botswana_gt.mat')['Botswana_gt']\n",
    "    return data, labels\n",
    "# without reduction of 200 channels to 30 channels, memory error while creating cube \n",
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)  # X :(145, 145, 30) --> (195, 195, 30) with window =25\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))  # (21025, 25, 25, 30)   \n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))  # (21025,)\n",
    "    patchIndex = 0\n",
    "    \n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]  \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]            \n",
    "            patchIndex = patchIndex + 1\n",
    "  \n",
    "    patchesData = np.expand_dims(patchesData, axis=-1)\n",
    "    return patchesData,patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input patches from the salinas dataset \n",
    "dataset1IP = 'Indian'                                         # 16 classes   \n",
    "sa_x1IP, sa_yIP = loadData(dataset1IP)                              #((512, 217, 204), (512, 217))\n",
    "sa_x2IP,pca = applyPCA(sa_x1IP,numComponents=30)                   # ((512, 217, 20), (512, 217))\n",
    "sa_XIP,sa_YIP = createImageCubes(sa_x2IP, sa_yIP, windowSize=15)   #(111104, 9, 9, 20, 1) (111104,)\n",
    "print(sa_XIP.shape,sa_YIP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches_class(X,Y,n) :\n",
    "  n_classes = n\n",
    "  patches_list = []\n",
    "  for i in range(1,n_classes+1):   # not considering class 0\n",
    "    patchesData_Ith_Label = X[Y==i,:,:,:,:]\n",
    "    patches_list.append(patchesData_Ith_Label)\n",
    "  return patches_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88875fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_salinas = patches_class(sa_X,sa_Y,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_IP = patches_class(sa_XIP,sa_YIP,16)#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "test_class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "train_patches_class = [patches_class_salinas[i] for i in train_class_indices]        #(10)\n",
    "test_patches_class = [patches_class_IP[i] for i in test_class_indices]        #(6) \n",
    "train_class_labels = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]   \n",
    "test_class_labels = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 15  # n_class\n",
    "K1 = 10   # n_support\n",
    "N = 20   # n_query\n",
    "tC = 16  # classes in a test episode\n",
    "im_height,im_width,im_depth = 15,15,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1974a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_opt = torch.optim.Adam(maml_model.parameters(), lr=0.0001, betas=(0.5, 0.999))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84296bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43944ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    np.random.shuffle(test_patches_class[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc498b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_set_5 = [[] for i in range(16)]\n",
    "for j in range(16) :\n",
    "  tune_set_5[j] = test_patches_class[j][:10,:,:,:,:]   # for each class first 5 samples taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tune_set_5))\n",
    "print(tune_set_5[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_episode(tune_set,tK,tN,test_class_labels) :\n",
    "  selected_classes = test_class_labels\n",
    "  support_labels  = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    np.random.shuffle(tune_set[y])    \n",
    "    support_imgs = tune_set[y][:tK,:,:,:,:]    #Support 1, Query 4\n",
    "    query_imgs = tune_set[y][tK:10,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(tN) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(tK) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(tC*tN,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(tC*tK,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels, list(selected_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd741d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixa = 'houston2/ckpts/ckpt399439479'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir2 = 'tuninghoustonip/ckpts'\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixa)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f32eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model=nn.Sequential(*list(maml_model.model.children())[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra0',nn.Linear(46656,256))\n",
    "maml_model.model.add_module('extra1',nn.Dropout(0.5))\n",
    "maml_model.model.add_module('extra2',nn.Linear(256,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra4',nn.Linear(128,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c739d80-fc30-43ba-b83d-d01d3d568523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img, length, num_band):\n",
    "\n",
    "\n",
    "    c, h, w = np.shape(img)[2], np.shape(img)[3], np.shape(img)[4]\n",
    "\n",
    "    data = img\n",
    "    RandPerm = np.random.permutation(c)\n",
    "    for i in range(len(RandPerm)//num_band):\n",
    "        img_c = img[RandPerm[i], :, :]\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "\n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "\n",
    "        mask[y1: y2, x1: x2] = 0\n",
    "\n",
    "        img_c *= mask\n",
    "        img_c = img_c[np.newaxis, :, :]\n",
    "        data[RandPerm[i], :, :] = img_c\n",
    "\n",
    "    img[2]=data[0]\n",
    "    img[3]=data[1]\n",
    "    img[4]=data[2]\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "n_episodes = 300\n",
    "epochs = 300\n",
    "import higher\n",
    "n_tasks = 16\n",
    "K2 = 5\n",
    "N2 = 5\n",
    "\n",
    "for k in range(epochs) :\n",
    "    tune_accuracies = []\n",
    "    maml_model.train()\n",
    "    total_loss = 0\n",
    "    accuracies = []\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        query_patches, support_patches, query_labels, support_labels, selected_classes = tune_episode(tune_set_5,5,5,test_class_labels)        \n",
    "        support_patches = cutout(support_patches, 2, 10)\n",
    "        query_patches = cutout(query_patches, 2, 10)\n",
    "        support_y = np.zeros((int(C*K2),C))\n",
    "        support_patches = support_patches.to(device)\n",
    "        query_patches = query_patches.to(device)                                           \n",
    "        for i in range(int(C*K2)) :\n",
    "          x = selected_classes.index(support_labels[i])                           # creation of 1-hot for true labels\n",
    "          support_y[i][x] = 1. \n",
    "        support_y = torch.from_numpy(support_y).to(device)\n",
    "        query_y = np.zeros((int(C*N2),C))                                           \n",
    "        for i in range(int(C*N2)) :\n",
    "          x = selected_classes.index(query_labels[i])                           # creation of 1-hot for true labels\n",
    "          query_y[i][x] = 1.\n",
    "        query_y = torch.from_numpy(query_y).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(support_patches)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss)\n",
    "        q_logits = fnet(query_patches)\n",
    "        q_real = query_y.argmax(axis=1)\n",
    "        q_real = (q_real).long()\n",
    "        q_loss = F.cross_entropy(q_logits,q_real)\n",
    "        qzq2_loss = q_loss\n",
    "        qzq2_loss.detach()\n",
    "        total_loss += qzq2_loss\n",
    "        qzq2_loss.backward()\n",
    "        eq = (q_logits.argmax(dim=1) == q_real).sum().item()\n",
    "        accuracy = eq/len(q_real)  \n",
    "        tune_accuracies.append(accuracy)\n",
    "    meta_opt.step()\n",
    "    tune_accuracies = torch.from_numpy(np.asarray(tune_accuracies))\n",
    "    print(k,'Loss',total_loss,..., 'Accuracy', torch.mean(tune_accuracies))\n",
    "    if (k+1)%2==0 :\n",
    "       torch.save({'model_state_dict': maml_model.state_dict(),\n",
    "            'optimizer_state_dict': meta_opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "            }, checkpoint_prefix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_episode(test_patches_class,test_class_labels,test_C,test_K) :\n",
    "  selected_classes = test_class_labels # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  support_labels = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    support_imgs = test_patches_class[y][:test_K,:,:,:,:]\n",
    "    query_imgs = test_patches_class[y][test_K:,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(query_imgs.shape[0]) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(test_K) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  x = len(query_labels)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(x,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(test_C*test_K,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels,x, list(selected_classes)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbcb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tquery_patches, tsupport_patches, tquery_labels, tsupport_labels, x, tselected_classes = test_episode(test_patches_class,test_class_labels,16,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixb = 'tuninghoustonip/ckpts/ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixb)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6505df-07e0-4635-acfb-b0a900f824f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C = 16\n",
    "for epoch in range(1): \n",
    "    import higher   \n",
    "    n_tasks = 1\n",
    "    total_loss = 0\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1, selected_classes1 = test_episode(test_patches_class,test_class_labels,16,5)        \n",
    "        support_y1 = np.zeros((int(C*K1),C))\n",
    "        tsupport_patches1 = tsupport_patches1.to(device)\n",
    "        tquery_patches1 = tquery_patches1.to(device)                                             \n",
    "        for i in range(int(C*K1)) :\n",
    "          x = selected_classes1.index(support_labels1[i])                           # creation of 1-hot for true labels\n",
    "          support_y1[i][x] = 1. \n",
    "        support_y1 = torch.from_numpy(support_y1).to(device)\n",
    "        query_y1 = np.zeros((int(x1),C))                                         \n",
    "        for i in range(int(x1)) :\n",
    "          x = selected_classes1.index(query_labels1[i])                           # creation of 1-hot for true labels\n",
    "          query_y1[i][x] = 1.\n",
    "        query_y1 = torch.from_numpy(query_y1).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(tsupport_patches1)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y1.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss2 = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss2)\n",
    "        q_logits1 = fnet(tquery_patches1)\n",
    "        q_real1 = query_y1.argmax(axis=1)\n",
    "        q_real1 = (q_real1).long()\n",
    "        q_loss = F.cross_entropy(q_logits1,q_real1)\n",
    "        qzq3_loss = q_loss\n",
    "        qzq3_loss.detach()\n",
    "        total_loss += qzq3_loss\n",
    "        #q_loss.backward()\n",
    "        eq1 = (q_logits1.argmax(dim=1) == q_real1).sum().item()\n",
    "        accuracy1 = eq1/len(q_real1)  \n",
    "        print(accuracy1) \n",
    "        mean_correct_class = [[] for i in range(C)]\n",
    "        mean_correct_pred = [[] for i in range(C)]\n",
    "        classwise_mean_acc = [[] for i in range(C)]\n",
    "        q_pred = q_logits1.argmax(dim=1)\n",
    "        for i in range(int(x1)):\n",
    "          x = selected_classes1.index(query_labels1[i])\n",
    "          mean_correct_class[x].append('4')\n",
    "          if(q_pred[i] == x) :\n",
    "            mean_correct_pred[x].append('4')\n",
    "        for i in range(C) :\n",
    "           z = len(mean_correct_pred[i])/len(mean_correct_class[i])\n",
    "           classwise_mean_acc[i].append(z)\n",
    "           print(classwise_mean_acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4de2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

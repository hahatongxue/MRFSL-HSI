{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os \n",
    "import scipy.io as sio\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables   \n",
    "im_width, im_height, im_depth, im_channel = 11,11,30,1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(MAML,self).__init__()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    layers = [nn.Conv3d(1,8,(7,3,3))]\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(8))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(8,16,(5,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(16))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(16,32,(3,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(32))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(14400,256))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(256,128))\n",
    "    layers.append(nn.Linear(128,15))\n",
    "    self.model = nn.Sequential(*layers)\n",
    "  def forward(self,x) :\n",
    "    y = self.model(x)\n",
    "    z = self.softmax(y)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model = MAML().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de623c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat('Houston.mat')['Houston']\n",
    "        labels = sio.loadmat('Houston_gt.mat')['Houston_gt']\n",
    "    if name == 'salinas' :\n",
    "        data = sio.loadmat('Salinas.mat')['salinas']\n",
    "        labels = sio.loadmat('Salinas_gt.mat')['salinas_gt']\n",
    "    if name == 'pavia' :\n",
    "        data = sio.loadmat('PaviaU.mat')['paviaU']\n",
    "        labels = sio.loadmat('PaviaU_gt.mat')['paviaU_gt']\n",
    "    if name == 'ksc' :\n",
    "        data = sio.loadmat('KSC.mat')['KSC']\n",
    "        labels = sio.loadmat('KSC_gt.mat')['KSC_gt']\n",
    "    if name == 'botswana' :\n",
    "        data = sio.loadmat('Botswana.mat')['Botswana']\n",
    "        labels = sio.loadmat('Botswana_gt.mat')['Botswana_gt']\n",
    "    return data, labels\n",
    "# without reduction of 200 channels to 30 channels, memory error while creating cube \n",
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)  # X :(145, 145, 30) --> (195, 195, 30) with window =25\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))  # (21025, 25, 25, 30)   \n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))  # (21025,)\n",
    "    patchIndex = 0\n",
    "    \n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]  \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]            \n",
    "            patchIndex = patchIndex + 1\n",
    "  \n",
    "    patchesData = np.expand_dims(patchesData, axis=-1)\n",
    "    return patchesData,patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input patches from the salinas dataset \n",
    "dataset1 = 'IP'                                         # 16 classes   \n",
    "sa_x1, sa_y = loadData(dataset1)                              #((512, 217, 204), (512, 217))\n",
    "sa_x2,pca = applyPCA(sa_x1,numComponents=30)                   # ((512, 217, 20), (512, 217))\n",
    "sa_X,sa_Y = createImageCubes(sa_x2, sa_y, windowSize=11)   #(111104, 9, 9, 20, 1) (111104,)\n",
    "print(sa_X.shape,sa_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input patches from the salinas dataset \n",
    "dataset1IP = 'salinas'                                         # 16 classes   \n",
    "sa_x1IP, sa_yIP = loadData(dataset1IP)                              #((512, 217, 204), (512, 217))\n",
    "sa_x2IP,pca = applyPCA(sa_x1IP,numComponents=30)                   # ((512, 217, 20), (512, 217))\n",
    "sa_XIP,sa_YIP = createImageCubes(sa_x2IP, sa_yIP, windowSize=11)   #(111104, 9, 9, 20, 1) (111104,)\n",
    "print(sa_XIP.shape,sa_YIP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8418685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches_class(X,Y,n) :\n",
    "  n_classes = n\n",
    "  patches_list = []\n",
    "  for i in range(1,n_classes+1):   # not considering class 0\n",
    "    patchesData_Ith_Label = X[Y==i,:,:,:,:]\n",
    "    patches_list.append(patchesData_Ith_Label)\n",
    "  return patches_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_salinas = patches_class(sa_X,sa_Y,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_IP = patches_class(sa_XIP,sa_YIP,16)#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "test_class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "train_patches_class = [patches_class_salinas[i] for i in train_class_indices]        #(10)\n",
    "test_patches_class = [patches_class_IP[i] for i in test_class_indices]        #(6) \n",
    "train_class_labels = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]   \n",
    "test_class_labels = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 15  # n_class\n",
    "K1 = 10   # n_support\n",
    "N = 20   # n_query\n",
    "tC = 16  # classes in a test episode\n",
    "im_height,im_width,im_depth = 11,11,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_episode(patches_list,K,C,N,class_labels) :\n",
    "  selected_classes = class_labels\n",
    "  tsupport_patches = []\n",
    "  tquery_patches = []\n",
    "  query_labels = []\n",
    "  support_labels = []\n",
    "  for x in selected_classes :\n",
    "    sran_indices = np.random.choice(len(patches_list[x-1]),K,replace=False)  # for class no X-1: select random sample no\n",
    "    support_patches = patches_list[x-1][sran_indices,:,:,:,:]\n",
    "    qran_indices = np.random.choice(len(patches_list[x-1]),N,replace=False)  # N Samples for Query\n",
    "    query_patches = patches_list[x-1][qran_indices,:,:,:,:]\n",
    "    for i in range(N) :\n",
    "      query_labels.append(x)   \n",
    "    for i in range(K) :\n",
    "      support_labels.append(x)    \n",
    "    tquery_patches.extend(query_patches)\n",
    "    tsupport_patches.extend(support_patches)\n",
    "  temp1 = list(zip(tquery_patches, query_labels)) \n",
    "  random.shuffle(temp1)        \n",
    "  tquery_patches, query_labels = zip(*temp1)\n",
    "  temp2 = list(zip(tsupport_patches, support_labels)) \n",
    "  random.shuffle(temp2)        \n",
    "  tsupport_patches, support_labels = zip(*temp2)\n",
    "  tquery_patches = torch.from_numpy(np.reshape(np.asarray(tquery_patches, dtype=np.float32),(C*N,im_height,im_width,im_depth,1)))\n",
    "  tsupport_patches = torch.from_numpy(np.reshape(np.asarray(tsupport_patches, dtype=np.float32),(C*K,im_height,im_width,im_depth,1)))\n",
    "  tquery_patches = tquery_patches.permute(0,4,3,2,1)\n",
    "  tsupport_patches = tsupport_patches.permute(0,4,3,2,1)\n",
    "  return tquery_patches, tsupport_patches, query_labels, support_labels, selected_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eebf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tquery_patches, tsupport_patches, query_labels, support_labels, selected_classes = new_episode(patches_class_salinas,K1,C,N,train_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_opt = torch.optim.Adam(maml_model.parameters(), lr=0.0001, betas=(0.5, 0.999))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cf26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir1 = 'houston2/ckpts'\n",
    "checkpoint_prefix1 = os.path.join(checkpoint_dir1, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    np.random.shuffle(test_patches_class[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90886d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_set_5 = [[] for i in range(16)]\n",
    "for j in range(16) :\n",
    "  tune_set_5[j] = test_patches_class[j][:10,:,:,:,:]   # for each class first 5 samples taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tune_set_5))\n",
    "print(tune_set_5[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_episode(tune_set,tK,tN,test_class_labels) :\n",
    "  selected_classes = test_class_labels\n",
    "  support_labels  = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    np.random.shuffle(tune_set[y])    \n",
    "    support_imgs = tune_set[y][:tK,:,:,:,:]    #Support 1, Query 4\n",
    "    query_imgs = tune_set[y][tK:10,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(tN) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(tK) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(tC*tN,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(tC*tK,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels, list(selected_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixa = 'houston2/ckpts/ckpt399439479'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir2 = 'tuninghouston/ckpts'\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17822ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixa)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model=nn.Sequential(*list(maml_model.model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra',nn.Linear(128,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9882a-1405-41c3-ba43-1bd5b9cfc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img, length, num_band):\n",
    "\n",
    "\n",
    "    c, h, w = np.shape(img)[2], np.shape(img)[3], np.shape(img)[4]\n",
    "\n",
    "    data = img\n",
    "    RandPerm = np.random.permutation(c)\n",
    "    for i in range(len(RandPerm)//num_band):\n",
    "        img_c = img[RandPerm[i], :, :]\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "\n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "\n",
    "        mask[y1: y2, x1: x2] = 0\n",
    "\n",
    "        img_c *= mask\n",
    "        img_c = img_c[np.newaxis, :, :]\n",
    "        data[RandPerm[i], :, :] = img_c\n",
    "        \n",
    "\n",
    "    img[2]=data[0]\n",
    "    img[3]=data[1]\n",
    "    img[4]=data[2]\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e93e3d-b3df-4b39-91df-506ab5243866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "n_episodes = 300\n",
    "epochs = 300\n",
    "import higher\n",
    "n_tasks = 16\n",
    "K2 = 5\n",
    "N2 = 5\n",
    "\n",
    "for k in range(epochs) :\n",
    "    tune_accuracies = []\n",
    "    maml_model.train()\n",
    "    total_loss = 0\n",
    "    accuracies = []\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        query_patches, support_patches, query_labels, support_labels, selected_classes = tune_episode(tune_set_5,5,5,test_class_labels) \n",
    "        support_patches = cutout(support_patches, 2, 10)\n",
    "        query_patches = cutout(query_patches, 2, 10)\n",
    "        support_y = np.zeros((int(C*K2),C))\n",
    "        support_patches = support_patches.to(device)\n",
    "        query_patches = query_patches.to(device)                                           \n",
    "        for i in range(int(C*K2)) :\n",
    "          x = selected_classes.index(support_labels[i])                           # creation of 1-hot for true labels\n",
    "          support_y[i][x] = 1. \n",
    "        support_y = torch.from_numpy(support_y).to(device)\n",
    "        query_y = np.zeros((int(C*N2),C))                                           \n",
    "        for i in range(int(C*N2)) :\n",
    "          x = selected_classes.index(query_labels[i])                           # creation of 1-hot for true labels\n",
    "          query_y[i][x] = 1.\n",
    "        query_y = torch.from_numpy(query_y).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(support_patches)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss)\n",
    "        q_logits = fnet(query_patches)\n",
    "        q_real = query_y.argmax(axis=1)\n",
    "        q_real = (q_real).long()\n",
    "        q_loss = F.cross_entropy(q_logits,q_real)\n",
    "        qzq2_loss = q_loss\n",
    "        qzq2_loss.detach()\n",
    "        total_loss += qzq2_loss\n",
    "        qzq2_loss.backward()\n",
    "        eq = (q_logits.argmax(dim=1) == q_real).sum().item()\n",
    "        accuracy = eq/len(q_real)  \n",
    "        tune_accuracies.append(accuracy)\n",
    "    meta_opt.step()\n",
    "    tune_accuracies = torch.from_numpy(np.asarray(tune_accuracies))\n",
    "    print(k,'Loss',total_loss,..., 'Accuracy', torch.mean(tune_accuracies))\n",
    "    if (k+1)%2==0 :\n",
    "       torch.save({'model_state_dict': maml_model.state_dict(),\n",
    "            'optimizer_state_dict': meta_opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "            }, checkpoint_prefix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3df137-5861-4dd8-9ca5-35a74b2ae729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_episode(test_patches_class,test_class_labels,test_C,test_K) :\n",
    "  selected_classes = test_class_labels # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  support_labels = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    support_imgs = test_patches_class[y][:test_K,:,:,:,:]\n",
    "    query_imgs = test_patches_class[y][test_K:,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(query_imgs.shape[0]) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(test_K) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  x = len(query_labels)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(x,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(test_C*test_K,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels,x, list(selected_classes)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a25632-9393-4d5e-b090-d73a8d1508a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixb = 'tuninghouston/ckpts/ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixb)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5 \n",
    "#K1 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2935453-921c-4b5b-a2a9-abaefdb978e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "C = 16\n",
    "for epoch in range(1): \n",
    "    import higher   \n",
    "    n_tasks = 1\n",
    "    total_loss = 0\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1, selected_classes1 = test_episode(test_patches_class,test_class_labels,16,5)#10        \n",
    "        support_y1 = np.zeros((int(C*K1),C))\n",
    "        tsupport_patches1 = tsupport_patches1.to(device)\n",
    "        tquery_patches1 = tquery_patches1.to(device)                                             \n",
    "        for i in range(int(C*K1)) :\n",
    "          x = selected_classes1.index(support_labels1[i])                           # creation of 1-hot for true labels\n",
    "          support_y1[i][x] = 1. \n",
    "        support_y1 = torch.from_numpy(support_y1).to(device)\n",
    "        query_y1 = np.zeros((int(x1),C))                                         \n",
    "        for i in range(int(x1)) :\n",
    "          x = selected_classes1.index(query_labels1[i])                           # creation of 1-hot for true labels\n",
    "          query_y1[i][x] = 1.\n",
    "        query_y1 = torch.from_numpy(query_y1).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(tsupport_patches1)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y1.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss2 = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss2)\n",
    "        q_logits1 = fnet(tquery_patches1)\n",
    "        q_real1 = query_y1.argmax(axis=1)\n",
    "        q_real1 = (q_real1).long()\n",
    "        q_loss = F.cross_entropy(q_logits1,q_real1)\n",
    "        qzq3_loss = q_loss\n",
    "        qzq3_loss.detach()\n",
    "        total_loss += qzq3_loss\n",
    "        #q_loss.backward()\n",
    "        eq1 = (q_logits1.argmax(dim=1) == q_real1).sum().item()\n",
    "        accuracy1 = eq1/len(q_real1)  \n",
    "        print(accuracy1) \n",
    "        mean_correct_class = [[] for i in range(C)]\n",
    "        mean_correct_pred = [[] for i in range(C)]\n",
    "        classwise_mean_acc = [[] for i in range(C)]\n",
    "        q_pred = q_logits1.argmax(dim=1)\n",
    "        for i in range(int(x1)):\n",
    "          x = selected_classes1.index(query_labels1[i])\n",
    "          mean_correct_class[x].append('4')\n",
    "          if(q_pred[i] == x) :\n",
    "            mean_correct_pred[x].append('4')\n",
    "        for i in range(C) :\n",
    "           z = len(mean_correct_pred[i])/len(mean_correct_class[i])\n",
    "           classwise_mean_acc[i].append(z)\n",
    "           print(classwise_mean_acc[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

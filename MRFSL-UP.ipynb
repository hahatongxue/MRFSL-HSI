{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba1a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os \n",
    "import scipy.io as sio\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ce9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef8c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables   \n",
    "im_width, im_height, im_depth, im_channel = 15,15,20,1  #size of the input salinas patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72861b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(MAML,self).__init__()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    layers = [nn.Conv3d(1,8,(7,3,3))]\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(8))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(8,16,(5,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(16))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Conv3d(16,32,(3,3,3)))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.BatchNorm3d(32))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(14400,256))\n",
    "    layers.append(nn.Dropout(0.5))\n",
    "    layers.append(nn.Linear(256,128))\n",
    "    layers.append(nn.Linear(128,15))\n",
    "    self.model = nn.Sequential(*layers)\n",
    "  def forward(self,x) :\n",
    "    y = self.model(x)\n",
    "    z = self.softmax(y)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942e4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3912de3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa891522",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model = MAML().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfcaf47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat('Houston.mat')['Houston']\n",
    "        labels = sio.loadmat('Houston_gt.mat')['Houston_gt']\n",
    "    if name == 'salinas' :\n",
    "        data = sio.loadmat('Salinas.mat')['salinas']\n",
    "        labels = sio.loadmat('Salinas_gt.mat')['salinas_gt']\n",
    "    if name == 'pavia' :\n",
    "        data = sio.loadmat('PaviaU.mat')['paviaU']\n",
    "        labels = sio.loadmat('PaviaU_gt.mat')['paviaU_gt']\n",
    "    if name == 'ksc' :\n",
    "        data = sio.loadmat('KSC.mat')['KSC']\n",
    "        labels = sio.loadmat('KSC_gt.mat')['KSC_gt']\n",
    "    if name == 'botswana' :\n",
    "        data = sio.loadmat('Botswana.mat')['Botswana']\n",
    "        labels = sio.loadmat('Botswana_gt.mat')['Botswana_gt']\n",
    "    return data, labels\n",
    "# without reduction of 200 channels to 30 channels, memory error while creating cube \n",
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)  # X :(145, 145, 30) --> (195, 195, 30) with window =25\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))  # (21025, 25, 25, 30)   \n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))  # (21025,)\n",
    "    patchIndex = 0\n",
    "    \n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]  \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]            \n",
    "            patchIndex = patchIndex + 1\n",
    "  \n",
    "    patchesData = np.expand_dims(patchesData, axis=-1)\n",
    "    return patchesData,patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9485408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207400, 15, 15, 20, 1) (207400,)\n"
     ]
    }
   ],
   "source": [
    "# creating input patches from the salinas dataset \n",
    "dataset1IP = 'pavia'                                         # 16 classes   \n",
    "sa_x1IP, sa_yIP = loadData(dataset1IP)                              #((512, 217, 204), (512, 217))\n",
    "sa_x2IP,pca = applyPCA(sa_x1IP,numComponents=20)                   # ((512, 217, 20), (512, 217))\n",
    "sa_XIP,sa_YIP = createImageCubes(sa_x2IP, sa_yIP, windowSize=15)   #(111104, 9, 9, 20, 1) (111104,)\n",
    "print(sa_XIP.shape,sa_YIP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839f2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches_class(X,Y,n) :\n",
    "  n_classes = n\n",
    "  patches_list = []\n",
    "  for i in range(1,n_classes+1):   # not considering class 0\n",
    "    patchesData_Ith_Label = X[Y==i,:,:,:,:]\n",
    "    patches_list.append(patchesData_Ith_Label)\n",
    "  return patches_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b141bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_class_IP = patches_class(sa_XIP,sa_YIP,9)#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a231fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_indices = [0,1,2,3,4,5,6,7,8]\n",
    "test_patches_class = [patches_class_IP[i] for i in test_class_indices]     \n",
    "test_class_labels = [1,2,3,4,5,6,7,8,9]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3bd3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 15  # n_class\n",
    "K1 = 10   # n_support\n",
    "N = 20   # n_query\n",
    "tC = 9  # classes in a test episode\n",
    "im_height,im_width,im_depth = 15,15,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44adc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_opt = torch.optim.Adam(maml_model.parameters(), lr=0.001, betas=(0.5, 0.999))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a907148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    np.random.shuffle(test_patches_class[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca83e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_set_5 = [[] for i in range(9)]\n",
    "for j in range(9) :\n",
    "  tune_set_5[j] = test_patches_class[j][:10,:,:,:,:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d36f0192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(10, 15, 15, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(tune_set_5))\n",
    "print(tune_set_5[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d4a405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a78bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_episode(tune_set,tK,tN,test_class_labels) :\n",
    "  selected_classes = test_class_labels\n",
    "  support_labels  = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    np.random.shuffle(tune_set[y])    \n",
    "    support_imgs = tune_set[y][:tK,:,:,:,:]    #Support 1, Query 4\n",
    "    query_imgs = tune_set[y][tK:10,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(tN) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(tK) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(tC*tN,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(tC*tK,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels, list(selected_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0fb3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixa = 'houston2/ckpts/ckpt399439479'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83ce01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir2 = 'paviacutout/ckpts'\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c99480b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixa)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16a05147",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model=nn.Sequential(*list(maml_model.model.children())[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2783b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra0',nn.Linear(20736,256))\n",
    "maml_model.model.add_module('extra1',nn.Dropout(0.5))\n",
    "maml_model.model.add_module('extra2',nn.Linear(256,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1bdd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_model.model.add_module('extra4',nn.Linear(128,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "622badf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b17f02f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAML(\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (model): Sequential(\n",
       "    (0): Conv3d(1, 8, kernel_size=(7, 3, 3), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Conv3d(8, 16, kernel_size=(5, 3, 3), stride=(1, 1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Flatten(start_dim=1, end_dim=-1)\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (extra0): Linear(in_features=20736, out_features=256, bias=True)\n",
       "    (extra1): Dropout(p=0.5, inplace=False)\n",
       "    (extra2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (extra4): Linear(in_features=128, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maml_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adf36fe3-3855-48eb-92c2-701800a4d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img, length, num_band):\n",
    "\n",
    "\n",
    "    c, h, w = np.shape(img)[2], np.shape(img)[3], np.shape(img)[4]\n",
    "\n",
    "    data = img\n",
    "    RandPerm = np.random.permutation(c)\n",
    "    for i in range(len(RandPerm)//num_band):\n",
    "        img_c = img[RandPerm[i], :, :]\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "\n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "\n",
    "        mask[y1: y2, x1: x2] = 0\n",
    "\n",
    "        img_c *= mask\n",
    "        img_c = img_c[np.newaxis, :, :]\n",
    "        data[RandPerm[i], :, :] = img_c\n",
    "        \n",
    "    img[2]=data[0]\n",
    "    img[3]=data[1]\n",
    "    img[4]=data[2]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f70cb50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss tensor(15.8040, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6938, dtype=torch.float64)\n",
      "1 Loss tensor(15.8473, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6741, dtype=torch.float64)\n",
      "2 Loss tensor(15.7171, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.6864, dtype=torch.float64)\n",
      "3 Loss tensor(15.4394, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7309, dtype=torch.float64)\n",
      "4 Loss tensor(15.3746, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7333, dtype=torch.float64)\n",
      "5 Loss tensor(15.3332, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7235, dtype=torch.float64)\n",
      "6 Loss tensor(15.2819, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7358, dtype=torch.float64)\n",
      "7 Loss tensor(15.1375, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7556, dtype=torch.float64)\n",
      "8 Loss tensor(15.3206, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7333, dtype=torch.float64)\n",
      "9 Loss tensor(15.1452, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7506, dtype=torch.float64)\n",
      "10 Loss tensor(15.2741, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7235, dtype=torch.float64)\n",
      "11 Loss tensor(15.1190, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7457, dtype=torch.float64)\n",
      "12 Loss tensor(15.0740, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7556, dtype=torch.float64)\n",
      "13 Loss tensor(15.0289, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7654, dtype=torch.float64)\n",
      "14 Loss tensor(15.0308, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7457, dtype=torch.float64)\n",
      "15 Loss tensor(14.9923, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7630, dtype=torch.float64)\n",
      "16 Loss tensor(14.9516, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7457, dtype=torch.float64)\n",
      "17 Loss tensor(14.9352, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7679, dtype=torch.float64)\n",
      "18 Loss tensor(14.9801, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7506, dtype=torch.float64)\n",
      "19 Loss tensor(14.8845, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7753, dtype=torch.float64)\n",
      "20 Loss tensor(14.9042, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7802, dtype=torch.float64)\n",
      "21 Loss tensor(14.8658, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7580, dtype=torch.float64)\n",
      "22 Loss tensor(14.8625, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7630, dtype=torch.float64)\n",
      "23 Loss tensor(14.9072, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7457, dtype=torch.float64)\n",
      "24 Loss tensor(14.8249, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7654, dtype=torch.float64)\n",
      "25 Loss tensor(14.6674, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7951, dtype=torch.float64)\n",
      "26 Loss tensor(14.6315, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "27 Loss tensor(14.8000, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7802, dtype=torch.float64)\n",
      "28 Loss tensor(14.7532, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7728, dtype=torch.float64)\n",
      "29 Loss tensor(14.7294, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7877, dtype=torch.float64)\n",
      "30 Loss tensor(14.7861, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7827, dtype=torch.float64)\n",
      "31 Loss tensor(14.7157, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7679, dtype=torch.float64)\n",
      "32 Loss tensor(14.6894, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8049, dtype=torch.float64)\n",
      "33 Loss tensor(14.5936, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8025, dtype=torch.float64)\n",
      "34 Loss tensor(14.7468, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7926, dtype=torch.float64)\n",
      "35 Loss tensor(14.7210, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7778, dtype=torch.float64)\n",
      "36 Loss tensor(14.7075, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7802, dtype=torch.float64)\n",
      "37 Loss tensor(14.5670, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "38 Loss tensor(14.7694, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7852, dtype=torch.float64)\n",
      "39 Loss tensor(14.5696, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8074, dtype=torch.float64)\n",
      "40 Loss tensor(14.7881, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7802, dtype=torch.float64)\n",
      "41 Loss tensor(14.5805, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "42 Loss tensor(14.5786, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8049, dtype=torch.float64)\n",
      "43 Loss tensor(14.5646, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8074, dtype=torch.float64)\n",
      "44 Loss tensor(14.5021, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8173, dtype=torch.float64)\n",
      "45 Loss tensor(14.5795, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8099, dtype=torch.float64)\n",
      "46 Loss tensor(14.5131, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8222, dtype=torch.float64)\n",
      "47 Loss tensor(14.7067, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7753, dtype=torch.float64)\n",
      "48 Loss tensor(14.5801, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8025, dtype=torch.float64)\n",
      "49 Loss tensor(14.6467, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "50 Loss tensor(14.5411, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7926, dtype=torch.float64)\n",
      "51 Loss tensor(14.5725, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7901, dtype=torch.float64)\n",
      "52 Loss tensor(14.3850, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8272, dtype=torch.float64)\n",
      "53 Loss tensor(14.6277, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8099, dtype=torch.float64)\n",
      "54 Loss tensor(14.4697, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8198, dtype=torch.float64)\n",
      "55 Loss tensor(14.4931, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8198, dtype=torch.float64)\n",
      "56 Loss tensor(14.5725, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8049, dtype=torch.float64)\n",
      "57 Loss tensor(14.5479, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8000, dtype=torch.float64)\n",
      "58 Loss tensor(14.4955, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8148, dtype=torch.float64)\n",
      "59 Loss tensor(14.7583, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7877, dtype=torch.float64)\n",
      "60 Loss tensor(14.4206, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8099, dtype=torch.float64)\n",
      "61 Loss tensor(14.5494, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8074, dtype=torch.float64)\n",
      "62 Loss tensor(14.5390, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8049, dtype=torch.float64)\n",
      "63 Loss tensor(14.4913, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8025, dtype=torch.float64)\n",
      "64 Loss tensor(14.4282, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8370, dtype=torch.float64)\n",
      "65 Loss tensor(14.3802, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8198, dtype=torch.float64)\n",
      "66 Loss tensor(14.5130, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8049, dtype=torch.float64)\n",
      "67 Loss tensor(14.3415, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8247, dtype=torch.float64)\n",
      "68 Loss tensor(14.3676, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8420, dtype=torch.float64)\n",
      "69 Loss tensor(14.4943, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8123, dtype=torch.float64)\n",
      "70 Loss tensor(14.3742, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8296, dtype=torch.float64)\n",
      "71 Loss tensor(14.2760, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8296, dtype=torch.float64)\n",
      "72 Loss tensor(14.2403, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "73 Loss tensor(14.5220, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8049, dtype=torch.float64)\n",
      "74 Loss tensor(14.3621, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8296, dtype=torch.float64)\n",
      "75 Loss tensor(14.2997, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "76 Loss tensor(14.3233, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "77 Loss tensor(14.2646, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8667, dtype=torch.float64)\n",
      "78 Loss tensor(14.3116, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8321, dtype=torch.float64)\n",
      "79 Loss tensor(14.4470, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8198, dtype=torch.float64)\n",
      "80 Loss tensor(14.3807, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "81 Loss tensor(14.2039, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8494, dtype=torch.float64)\n",
      "82 Loss tensor(14.3447, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "83 Loss tensor(14.2420, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8420, dtype=torch.float64)\n",
      "84 Loss tensor(14.1995, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "85 Loss tensor(14.4009, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8296, dtype=torch.float64)\n",
      "86 Loss tensor(14.3927, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8123, dtype=torch.float64)\n",
      "87 Loss tensor(14.2400, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8519, dtype=torch.float64)\n",
      "88 Loss tensor(14.2723, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8444, dtype=torch.float64)\n",
      "89 Loss tensor(14.2463, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8543, dtype=torch.float64)\n",
      "90 Loss tensor(14.1676, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8593, dtype=torch.float64)\n",
      "91 Loss tensor(14.2764, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "92 Loss tensor(14.5157, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.7975, dtype=torch.float64)\n",
      "93 Loss tensor(14.2060, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8444, dtype=torch.float64)\n",
      "94 Loss tensor(14.3464, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "95 Loss tensor(14.2159, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8543, dtype=torch.float64)\n",
      "96 Loss tensor(14.1870, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8691, dtype=torch.float64)\n",
      "97 Loss tensor(14.2723, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "98 Loss tensor(14.2176, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8296, dtype=torch.float64)\n",
      "99 Loss tensor(14.2127, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "100 Loss tensor(14.1808, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8494, dtype=torch.float64)\n",
      "101 Loss tensor(14.2503, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8420, dtype=torch.float64)\n",
      "102 Loss tensor(14.2123, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8420, dtype=torch.float64)\n",
      "103 Loss tensor(14.2204, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8519, dtype=torch.float64)\n",
      "104 Loss tensor(14.1623, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8494, dtype=torch.float64)\n",
      "105 Loss tensor(14.3117, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "106 Loss tensor(14.1955, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8395, dtype=torch.float64)\n",
      "107 Loss tensor(14.1725, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8370, dtype=torch.float64)\n",
      "108 Loss tensor(14.1744, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8494, dtype=torch.float64)\n",
      "109 Loss tensor(14.1531, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8494, dtype=torch.float64)\n",
      "110 Loss tensor(14.2224, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8519, dtype=torch.float64)\n",
      "111 Loss tensor(14.1224, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8543, dtype=torch.float64)\n",
      "112 Loss tensor(14.2720, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "113 Loss tensor(14.1425, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "114 Loss tensor(14.1989, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "115 Loss tensor(14.2009, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8519, dtype=torch.float64)\n",
      "116 Loss tensor(14.2094, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8444, dtype=torch.float64)\n",
      "117 Loss tensor(14.2159, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8420, dtype=torch.float64)\n",
      "118 Loss tensor(14.1927, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8543, dtype=torch.float64)\n",
      "119 Loss tensor(14.0484, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8667, dtype=torch.float64)\n",
      "120 Loss tensor(14.0224, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8568, dtype=torch.float64)\n",
      "121 Loss tensor(14.1383, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8444, dtype=torch.float64)\n",
      "122 Loss tensor(14.2719, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8346, dtype=torch.float64)\n",
      "123 Loss tensor(14.2161, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8444, dtype=torch.float64)\n",
      "124 Loss tensor(14.0697, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8741, dtype=torch.float64)\n",
      "125 Loss tensor(14.0834, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8519, dtype=torch.float64)\n",
      "126 Loss tensor(13.9652, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8765, dtype=torch.float64)\n",
      "127 Loss tensor(13.9785, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8568, dtype=torch.float64)\n",
      "128 Loss tensor(14.0488, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8691, dtype=torch.float64)\n",
      "129 Loss tensor(14.1763, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8543, dtype=torch.float64)\n",
      "130 Loss tensor(14.1195, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8469, dtype=torch.float64)\n",
      "131 Loss tensor(13.9869, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "132 Loss tensor(13.9792, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8716, dtype=torch.float64)\n",
      "133 Loss tensor(13.9657, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "134 Loss tensor(14.0527, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8519, dtype=torch.float64)\n",
      "135 Loss tensor(13.9279, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "136 Loss tensor(13.9754, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8815, dtype=torch.float64)\n",
      "137 Loss tensor(14.0077, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8716, dtype=torch.float64)\n",
      "138 Loss tensor(14.0461, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8568, dtype=torch.float64)\n",
      "139 Loss tensor(14.0088, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8716, dtype=torch.float64)\n",
      "140 Loss tensor(13.8959, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "141 Loss tensor(14.1871, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8494, dtype=torch.float64)\n",
      "142 Loss tensor(14.0378, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8691, dtype=torch.float64)\n",
      "143 Loss tensor(13.9688, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "144 Loss tensor(13.9490, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8815, dtype=torch.float64)\n",
      "145 Loss tensor(13.9732, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8691, dtype=torch.float64)\n",
      "146 Loss tensor(13.9064, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "147 Loss tensor(13.9722, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "148 Loss tensor(13.8751, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8815, dtype=torch.float64)\n",
      "149 Loss tensor(13.8290, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "150 Loss tensor(13.9945, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8889, dtype=torch.float64)\n",
      "151 Loss tensor(14.0060, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8667, dtype=torch.float64)\n",
      "152 Loss tensor(13.9786, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8716, dtype=torch.float64)\n",
      "153 Loss tensor(13.8973, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "154 Loss tensor(14.0066, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8691, dtype=torch.float64)\n",
      "155 Loss tensor(13.8916, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8840, dtype=torch.float64)\n",
      "156 Loss tensor(13.9901, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8593, dtype=torch.float64)\n",
      "157 Loss tensor(14.0734, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8765, dtype=torch.float64)\n",
      "158 Loss tensor(13.8376, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8840, dtype=torch.float64)\n",
      "159 Loss tensor(14.1166, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8568, dtype=torch.float64)\n",
      "160 Loss tensor(13.9611, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8815, dtype=torch.float64)\n",
      "161 Loss tensor(13.8259, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "162 Loss tensor(13.9380, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8716, dtype=torch.float64)\n",
      "163 Loss tensor(13.8777, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "164 Loss tensor(13.8846, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "165 Loss tensor(13.8533, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8864, dtype=torch.float64)\n",
      "166 Loss tensor(13.9285, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8667, dtype=torch.float64)\n",
      "167 Loss tensor(13.9618, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8840, dtype=torch.float64)\n",
      "168 Loss tensor(13.9585, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8716, dtype=torch.float64)\n",
      "169 Loss tensor(13.9388, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8765, dtype=torch.float64)\n",
      "170 Loss tensor(13.8567, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "171 Loss tensor(13.9086, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8815, dtype=torch.float64)\n",
      "172 Loss tensor(13.8559, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "173 Loss tensor(13.8421, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "174 Loss tensor(13.8550, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "175 Loss tensor(13.9075, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8741, dtype=torch.float64)\n",
      "176 Loss tensor(13.8313, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "177 Loss tensor(13.9241, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8840, dtype=torch.float64)\n",
      "178 Loss tensor(13.9736, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8642, dtype=torch.float64)\n",
      "179 Loss tensor(13.7784, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "180 Loss tensor(13.8251, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "181 Loss tensor(13.9479, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8642, dtype=torch.float64)\n",
      "182 Loss tensor(13.8531, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "183 Loss tensor(13.8787, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8864, dtype=torch.float64)\n",
      "184 Loss tensor(13.7897, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "185 Loss tensor(13.8544, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "186 Loss tensor(13.7534, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8988, dtype=torch.float64)\n",
      "187 Loss tensor(13.8430, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "188 Loss tensor(13.8536, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "189 Loss tensor(13.8166, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "190 Loss tensor(13.8508, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8840, dtype=torch.float64)\n",
      "191 Loss tensor(13.8412, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "192 Loss tensor(13.8429, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8889, dtype=torch.float64)\n",
      "193 Loss tensor(13.8766, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8864, dtype=torch.float64)\n",
      "194 Loss tensor(13.8786, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "195 Loss tensor(13.8956, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "196 Loss tensor(13.8077, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "197 Loss tensor(13.8427, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "198 Loss tensor(13.7639, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8988, dtype=torch.float64)\n",
      "199 Loss tensor(13.7216, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "200 Loss tensor(13.7988, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "201 Loss tensor(13.7836, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8988, dtype=torch.float64)\n",
      "202 Loss tensor(13.7959, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "203 Loss tensor(13.6157, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "204 Loss tensor(13.6974, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "205 Loss tensor(13.7160, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "206 Loss tensor(13.7942, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "207 Loss tensor(13.8439, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "208 Loss tensor(13.7504, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "209 Loss tensor(13.7741, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8988, dtype=torch.float64)\n",
      "210 Loss tensor(13.7314, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8889, dtype=torch.float64)\n",
      "211 Loss tensor(13.7002, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "212 Loss tensor(13.8299, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "213 Loss tensor(13.8049, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "214 Loss tensor(13.7580, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "215 Loss tensor(13.8236, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8938, dtype=torch.float64)\n",
      "216 Loss tensor(13.8408, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8864, dtype=torch.float64)\n",
      "217 Loss tensor(13.8943, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8790, dtype=torch.float64)\n",
      "218 Loss tensor(13.7035, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "219 Loss tensor(13.8583, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8864, dtype=torch.float64)\n",
      "220 Loss tensor(13.7408, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "221 Loss tensor(13.6530, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "222 Loss tensor(13.7623, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9037, dtype=torch.float64)\n",
      "223 Loss tensor(13.6428, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "224 Loss tensor(13.6450, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "225 Loss tensor(13.6612, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "226 Loss tensor(13.7168, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "227 Loss tensor(13.6802, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "228 Loss tensor(13.6418, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "229 Loss tensor(13.7204, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "230 Loss tensor(13.7234, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "231 Loss tensor(13.7977, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9037, dtype=torch.float64)\n",
      "232 Loss tensor(13.7532, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "233 Loss tensor(13.6834, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "234 Loss tensor(13.6665, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "235 Loss tensor(13.7092, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "236 Loss tensor(13.6791, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "237 Loss tensor(13.6349, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8963, dtype=torch.float64)\n",
      "238 Loss tensor(13.6449, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9062, dtype=torch.float64)\n",
      "239 Loss tensor(13.6164, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "240 Loss tensor(13.5750, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "241 Loss tensor(13.7233, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9037, dtype=torch.float64)\n",
      "242 Loss tensor(13.6376, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "243 Loss tensor(13.6246, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "244 Loss tensor(13.7028, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "245 Loss tensor(13.5823, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "246 Loss tensor(13.5634, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "247 Loss tensor(13.7210, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "248 Loss tensor(13.6189, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "249 Loss tensor(13.6940, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8988, dtype=torch.float64)\n",
      "250 Loss tensor(13.7406, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "251 Loss tensor(13.6665, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "252 Loss tensor(13.6457, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "253 Loss tensor(13.5891, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "254 Loss tensor(13.5941, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "255 Loss tensor(13.6133, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "256 Loss tensor(13.5980, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "257 Loss tensor(13.6293, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "258 Loss tensor(13.6243, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "259 Loss tensor(13.6044, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "260 Loss tensor(13.7889, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.8914, dtype=torch.float64)\n",
      "261 Loss tensor(13.6100, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "262 Loss tensor(13.7759, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9012, dtype=torch.float64)\n",
      "263 Loss tensor(13.5912, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "264 Loss tensor(13.5572, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "265 Loss tensor(13.5726, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "266 Loss tensor(13.5301, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "267 Loss tensor(13.6079, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "268 Loss tensor(13.5203, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "269 Loss tensor(13.5737, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "270 Loss tensor(13.5294, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "271 Loss tensor(13.6059, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "272 Loss tensor(13.5923, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "273 Loss tensor(13.6350, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "274 Loss tensor(13.6224, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "275 Loss tensor(13.6947, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "276 Loss tensor(13.5126, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "277 Loss tensor(13.5991, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "278 Loss tensor(13.4428, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "279 Loss tensor(13.5494, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "280 Loss tensor(13.5550, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "281 Loss tensor(13.6063, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "282 Loss tensor(13.5843, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "283 Loss tensor(13.5126, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "284 Loss tensor(13.4911, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "285 Loss tensor(13.5252, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "286 Loss tensor(13.5306, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "287 Loss tensor(13.5287, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "288 Loss tensor(13.6720, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "289 Loss tensor(13.5844, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9111, dtype=torch.float64)\n",
      "290 Loss tensor(13.4811, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "291 Loss tensor(13.5888, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "292 Loss tensor(13.5149, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "293 Loss tensor(13.5114, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "294 Loss tensor(13.5404, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "295 Loss tensor(13.5029, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "296 Loss tensor(13.5982, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "297 Loss tensor(13.4839, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "298 Loss tensor(13.6453, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "299 Loss tensor(13.5467, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "300 Loss tensor(13.4860, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "301 Loss tensor(13.5415, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9086, dtype=torch.float64)\n",
      "302 Loss tensor(13.5154, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "303 Loss tensor(13.5828, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "304 Loss tensor(13.5227, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "305 Loss tensor(13.5287, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "306 Loss tensor(13.5285, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "307 Loss tensor(13.5553, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "308 Loss tensor(13.5405, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "309 Loss tensor(13.5052, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "310 Loss tensor(13.6259, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "311 Loss tensor(13.5429, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "312 Loss tensor(13.5441, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "313 Loss tensor(13.4513, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "314 Loss tensor(13.4714, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "315 Loss tensor(13.4921, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "316 Loss tensor(13.4684, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "317 Loss tensor(13.5451, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "318 Loss tensor(13.5335, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "319 Loss tensor(13.4872, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "320 Loss tensor(13.4681, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "321 Loss tensor(13.5478, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9160, dtype=torch.float64)\n",
      "322 Loss tensor(13.5596, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9136, dtype=torch.float64)\n",
      "323 Loss tensor(13.4925, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "324 Loss tensor(13.4336, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "325 Loss tensor(13.4632, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "326 Loss tensor(13.4183, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "327 Loss tensor(13.4963, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "328 Loss tensor(13.4952, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "329 Loss tensor(13.4667, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "330 Loss tensor(13.4858, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "331 Loss tensor(13.4999, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "332 Loss tensor(13.4936, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "333 Loss tensor(13.4232, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "334 Loss tensor(13.5278, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "335 Loss tensor(13.5720, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "336 Loss tensor(13.3113, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9457, dtype=torch.float64)\n",
      "337 Loss tensor(13.3416, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "338 Loss tensor(13.4745, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "339 Loss tensor(13.4992, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "340 Loss tensor(13.3918, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "341 Loss tensor(13.3655, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "342 Loss tensor(13.4953, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "343 Loss tensor(13.5087, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "344 Loss tensor(13.4571, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "345 Loss tensor(13.4066, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "346 Loss tensor(13.4893, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9185, dtype=torch.float64)\n",
      "347 Loss tensor(13.4252, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "348 Loss tensor(13.4751, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "349 Loss tensor(13.4705, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "350 Loss tensor(13.4127, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "351 Loss tensor(13.5252, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "352 Loss tensor(13.4213, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "353 Loss tensor(13.4501, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "354 Loss tensor(13.4481, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "355 Loss tensor(13.4613, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "356 Loss tensor(13.5220, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "357 Loss tensor(13.4115, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "358 Loss tensor(13.4306, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "359 Loss tensor(13.3843, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "360 Loss tensor(13.4479, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9259, dtype=torch.float64)\n",
      "361 Loss tensor(13.4754, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "362 Loss tensor(13.4692, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "363 Loss tensor(13.4400, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9235, dtype=torch.float64)\n",
      "364 Loss tensor(13.3889, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "365 Loss tensor(13.4397, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "366 Loss tensor(13.3985, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "367 Loss tensor(13.3110, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "368 Loss tensor(13.4300, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "369 Loss tensor(13.3851, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "370 Loss tensor(13.3681, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "371 Loss tensor(13.3493, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "372 Loss tensor(13.4052, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "373 Loss tensor(13.3365, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "374 Loss tensor(13.4236, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "375 Loss tensor(13.3211, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "376 Loss tensor(13.4772, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "377 Loss tensor(13.4490, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9210, dtype=torch.float64)\n",
      "378 Loss tensor(13.4920, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "379 Loss tensor(13.3755, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "380 Loss tensor(13.2822, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "381 Loss tensor(13.4675, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "382 Loss tensor(13.3783, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "383 Loss tensor(13.3564, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "384 Loss tensor(13.3889, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "385 Loss tensor(13.3599, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "386 Loss tensor(13.4115, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "387 Loss tensor(13.3227, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "388 Loss tensor(13.3209, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "389 Loss tensor(13.3161, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "390 Loss tensor(13.4325, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "391 Loss tensor(13.4163, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "392 Loss tensor(13.4026, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "393 Loss tensor(13.3725, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "394 Loss tensor(13.3303, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "395 Loss tensor(13.3972, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "396 Loss tensor(13.4741, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "397 Loss tensor(13.3333, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "398 Loss tensor(13.3979, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "399 Loss tensor(13.4015, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "400 Loss tensor(13.3270, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "401 Loss tensor(13.3573, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "402 Loss tensor(13.2754, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "403 Loss tensor(13.3690, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "404 Loss tensor(13.3540, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "405 Loss tensor(13.3968, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "406 Loss tensor(13.4007, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "407 Loss tensor(13.4373, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "408 Loss tensor(13.2964, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "409 Loss tensor(13.3254, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "410 Loss tensor(13.3978, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "411 Loss tensor(13.3272, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "412 Loss tensor(13.4266, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "413 Loss tensor(13.3705, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "414 Loss tensor(13.4610, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "415 Loss tensor(13.3931, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "416 Loss tensor(13.3835, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "417 Loss tensor(13.2453, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9481, dtype=torch.float64)\n",
      "418 Loss tensor(13.2457, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9457, dtype=torch.float64)\n",
      "419 Loss tensor(13.4065, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "420 Loss tensor(13.3569, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "421 Loss tensor(13.3989, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "422 Loss tensor(13.2575, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "423 Loss tensor(13.3645, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "424 Loss tensor(13.3221, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "425 Loss tensor(13.3593, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "426 Loss tensor(13.3755, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "427 Loss tensor(13.3353, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "428 Loss tensor(13.3821, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "429 Loss tensor(13.2356, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "430 Loss tensor(13.3850, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "431 Loss tensor(13.3720, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "432 Loss tensor(13.4334, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "433 Loss tensor(13.3469, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "434 Loss tensor(13.2557, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "435 Loss tensor(13.3546, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "436 Loss tensor(13.3218, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "437 Loss tensor(13.3886, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "438 Loss tensor(13.4561, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "439 Loss tensor(13.2773, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "440 Loss tensor(13.4135, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "441 Loss tensor(13.3065, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "442 Loss tensor(13.3070, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "443 Loss tensor(13.3164, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "444 Loss tensor(13.3315, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "445 Loss tensor(13.3161, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "446 Loss tensor(13.3049, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "447 Loss tensor(13.2717, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "448 Loss tensor(13.2338, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "449 Loss tensor(13.3656, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "450 Loss tensor(13.3255, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "451 Loss tensor(13.3553, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "452 Loss tensor(13.2352, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "453 Loss tensor(13.3293, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "454 Loss tensor(13.2718, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "455 Loss tensor(13.3083, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "456 Loss tensor(13.2815, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9457, dtype=torch.float64)\n",
      "457 Loss tensor(13.3223, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "458 Loss tensor(13.2820, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "459 Loss tensor(13.3018, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "460 Loss tensor(13.3193, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "461 Loss tensor(13.4023, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "462 Loss tensor(13.4309, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "463 Loss tensor(13.2864, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "464 Loss tensor(13.3112, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "465 Loss tensor(13.3380, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "466 Loss tensor(13.2385, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9457, dtype=torch.float64)\n",
      "467 Loss tensor(13.3221, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "468 Loss tensor(13.2669, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "469 Loss tensor(13.2721, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "470 Loss tensor(13.2891, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "471 Loss tensor(13.3027, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "472 Loss tensor(13.3460, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "473 Loss tensor(13.4113, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "474 Loss tensor(13.3696, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "475 Loss tensor(13.2808, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "476 Loss tensor(13.3100, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "477 Loss tensor(13.3131, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "478 Loss tensor(13.3097, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "479 Loss tensor(13.2766, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "480 Loss tensor(13.2381, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "481 Loss tensor(13.3010, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "482 Loss tensor(13.2783, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "483 Loss tensor(13.3027, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "484 Loss tensor(13.2464, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "485 Loss tensor(13.3108, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "486 Loss tensor(13.3749, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9333, dtype=torch.float64)\n",
      "487 Loss tensor(13.3362, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9284, dtype=torch.float64)\n",
      "488 Loss tensor(13.2972, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "489 Loss tensor(13.2762, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "490 Loss tensor(13.2838, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9383, dtype=torch.float64)\n",
      "491 Loss tensor(13.2198, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "492 Loss tensor(13.2625, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "493 Loss tensor(13.3109, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "494 Loss tensor(13.3439, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9407, dtype=torch.float64)\n",
      "495 Loss tensor(13.3659, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "496 Loss tensor(13.3422, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9309, dtype=torch.float64)\n",
      "497 Loss tensor(13.2736, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n",
      "498 Loss tensor(13.2022, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9432, dtype=torch.float64)\n",
      "499 Loss tensor(13.1508, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9457, dtype=torch.float64)\n",
      "500 Loss tensor(13.3158, device='cuda:0', grad_fn=<AddBackward0>) Ellipsis Accuracy tensor(0.9358, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "n_episodes = 501\n",
    "epochs = 501\n",
    "import higher\n",
    "n_tasks = 9\n",
    "K2 = 5\n",
    "N2 = 5\n",
    "\n",
    "for k in range(epochs) :\n",
    "    tune_accuracies = []\n",
    "    maml_model.train()\n",
    "    total_loss = 0\n",
    "    accuracies = []\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        query_patches, support_patches, query_labels, support_labels, selected_classes = tune_episode(tune_set_5,5,5,test_class_labels)   \n",
    "        support_patches = cutout(support_patches, 2, 10)\n",
    "        query_patches = cutout(query_patches, 2, 10)\n",
    "        support_y = np.zeros((int(C*K2),C))\n",
    "        support_patches = support_patches.to(device)\n",
    "        query_patches = query_patches.to(device)                                           \n",
    "        for i in range(int(C*K2)) :\n",
    "          x = selected_classes.index(support_labels[i])                           # creation of 1-hot for true labels\n",
    "          support_y[i][x] = 1. \n",
    "        support_y = torch.from_numpy(support_y).to(device)\n",
    "        query_y = np.zeros((int(C*N2),C))                                           \n",
    "        for i in range(int(C*N2)) :\n",
    "          x = selected_classes.index(query_labels[i])                           # creation of 1-hot for true labels\n",
    "          query_y[i][x] = 1.\n",
    "        query_y = torch.from_numpy(query_y).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(support_patches)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss)\n",
    "        q_logits = fnet(query_patches)\n",
    "        q_real = query_y.argmax(axis=1)\n",
    "        q_real = (q_real).long()\n",
    "        q_loss = F.cross_entropy(q_logits,q_real)\n",
    "        qzq2_loss = q_loss\n",
    "        qzq2_loss.detach()\n",
    "        total_loss += qzq2_loss\n",
    "        qzq2_loss.backward()\n",
    "        eq = (q_logits.argmax(dim=1) == q_real).sum().item()\n",
    "        accuracy = eq/len(q_real)  \n",
    "        tune_accuracies.append(accuracy)\n",
    "    meta_opt.step()\n",
    "    tune_accuracies = torch.from_numpy(np.asarray(tune_accuracies))\n",
    "    print(k,'Loss',total_loss,..., 'Accuracy', torch.mean(tune_accuracies))\n",
    "    if (k+1)%2==0 :\n",
    "       torch.save({'model_state_dict': maml_model.state_dict(),\n",
    "            'optimizer_state_dict': meta_opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "            }, checkpoint_prefix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ae67faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_episode(test_patches_class,test_class_labels,test_C,test_K) :\n",
    "  selected_classes = test_class_labels # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  support_labels = []\n",
    "  query_labels = []\n",
    "  support_patches = []\n",
    "  query_patches = []\n",
    "  for x in selected_classes :\n",
    "    y = test_class_labels.index(x)\n",
    "    support_imgs = test_patches_class[y][:test_K,:,:,:,:]\n",
    "    query_imgs = test_patches_class[y][test_K:,:,:,:,:]\n",
    "    support_patches.extend(support_imgs)\n",
    "    query_patches.extend(query_imgs)\n",
    "    for i in range(query_imgs.shape[0]) :\n",
    "      query_labels.append(x)\n",
    "    for i in range(test_K) :\n",
    "      support_labels.append(x)\n",
    "  temp1 = list(zip(query_patches, query_labels)) \n",
    "  random.shuffle(temp1) \n",
    "  query_patches, query_labels = zip(*temp1)\n",
    "  x = len(query_labels)\n",
    "  query_patches = torch.from_numpy(np.reshape(np.asarray(query_patches,dtype=np.float32),(x,im_height,im_width,im_depth,1)))\n",
    "  support_patches = torch.from_numpy(np.reshape(np.asarray(support_patches,dtype=np.float32),(test_C*test_K,im_height,im_width,im_depth,1)))\n",
    "  query_patches = query_patches.permute(0,4,3,2,1)\n",
    "  support_patches = support_patches.permute(0,4,3,2,1)\n",
    "  return query_patches, support_patches, query_labels, support_labels,x, list(selected_classes)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3408b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tquery_patches, tsupport_patches, tquery_labels, tsupport_labels, x, tselected_classes = test_episode(test_patches_class,test_class_labels,16,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c5621cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefixb = 'paviacutout/ckpts/ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc0f7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tune = torch.load(checkpoint_prefixb)\n",
    "maml_model.load_state_dict(checkpoint_tune['model_state_dict'])\n",
    "meta_opt.load_state_dict(checkpoint_tune['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d6541fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa9a4d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAML(\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (model): Sequential(\n",
       "    (0): Conv3d(1, 8, kernel_size=(7, 3, 3), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Conv3d(8, 16, kernel_size=(5, 3, 3), stride=(1, 1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Flatten(start_dim=1, end_dim=-1)\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (extra0): Linear(in_features=20736, out_features=256, bias=True)\n",
       "    (extra1): Dropout(p=0.5, inplace=False)\n",
       "    (extra2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (extra4): Linear(in_features=128, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maml_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2280aa2e-4d36-4ea9-9edf-95ec6648862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8922328052233741\n",
      "[0.8214609115605191]\n",
      "[0.8848959450761639]\n",
      "[0.8839541547277937]\n",
      "[0.8865642366786531]\n",
      "[0.9970149253731343]\n",
      "[0.9629777070063694]\n",
      "[0.9932075471698113]\n",
      "[0.874082132172967]\n",
      "[0.9745222929936306]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C = 9\n",
    "for epoch in range(1): \n",
    "    import higher   \n",
    "    n_tasks = 1\n",
    "    total_loss = 0\n",
    "    n_inner_iter = 16\n",
    "    inner_opt = torch.optim.SGD(maml_model.parameters(), lr=1e-1)\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(n_tasks) :\n",
    "      with higher.innerloop_ctx(maml_model, inner_opt, copy_initial_weights=False) as (fnet, diffopt): \n",
    "        tquery_patches1, tsupport_patches1, query_labels1, support_labels1, x1, selected_classes1 = test_episode(test_patches_class,test_class_labels,9,5)        \n",
    "        support_y1 = np.zeros((int(C*K1),C))\n",
    "        tsupport_patches1 = tsupport_patches1.to(device)\n",
    "        tquery_patches1 = tquery_patches1.to(device)                                             \n",
    "        for i in range(int(C*K1)) :\n",
    "          x = selected_classes1.index(support_labels1[i])                           # creation of 1-hot for true labels\n",
    "          support_y1[i][x] = 1. \n",
    "        support_y1 = torch.from_numpy(support_y1).to(device)\n",
    "        query_y1 = np.zeros((int(x1),C))                                         \n",
    "        for i in range(int(x1)) :\n",
    "          x = selected_classes1.index(query_labels1[i])                           # creation of 1-hot for true labels\n",
    "          query_y1[i][x] = 1.\n",
    "        query_y1 = torch.from_numpy(query_y1).to(device)\n",
    "        for i in range(n_inner_iter) :\n",
    "          s_logits_t = fnet(tsupport_patches1)\n",
    "          i_loss = F.cross_entropy(s_logits_t,support_y1.argmax(axis=1))\n",
    "          z_loss2 = i_loss\n",
    "          z_loss2 = torch.mean(z_loss2)\n",
    "          diffopt.step(z_loss2)\n",
    "        q_logits1 = fnet(tquery_patches1)\n",
    "        q_real1 = query_y1.argmax(axis=1)\n",
    "        q_real1 = (q_real1).long()\n",
    "        q_loss = F.cross_entropy(q_logits1,q_real1)\n",
    "        qzq3_loss = q_loss\n",
    "        qzq3_loss.detach()\n",
    "        total_loss += qzq3_loss\n",
    "        #q_loss.backward()\n",
    "        eq1 = (q_logits1.argmax(dim=1) == q_real1).sum().item()\n",
    "        accuracy1 = eq1/len(q_real1)  \n",
    "        print(accuracy1) \n",
    "        mean_correct_class = [[] for i in range(C)]\n",
    "        mean_correct_pred = [[] for i in range(C)]\n",
    "        classwise_mean_acc = [[] for i in range(C)]\n",
    "        q_pred = q_logits1.argmax(dim=1)\n",
    "        for i in range(int(x1)):\n",
    "          x = selected_classes1.index(query_labels1[i])\n",
    "          mean_correct_class[x].append('4')\n",
    "          if(q_pred[i] == x) :\n",
    "            mean_correct_pred[x].append('4')\n",
    "        for i in range(C) :\n",
    "           z = len(mean_correct_pred[i])/len(mean_correct_class[i])\n",
    "           classwise_mean_acc[i].append(z)\n",
    "           print(classwise_mean_acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018073bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
